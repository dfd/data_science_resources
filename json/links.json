{
    "links": [
        {
            "author": "Allen Downey",
            "description": "\"Think Python is an introduction to Python programming for beginners. It starts with basic concepts of programming, and is carefully designed to define all terms when they are first used and to develop each new concept in a logical progression. Larger pieces, like recursion and object-oriented programming are divided into a sequence of smaller steps and introduced over the course of several chapters.\" Uses Python 3.",
            "tags": [
                "Python Textbooks",
                "Beginner Python"
            ],
            "title": "Think Python 2e",
            "url": "http://greenteapress.com/wp/think-python-2e/"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Python is an introduction to Python programming for beginners. It starts with basic concepts of programming, and is carefully designed to define all terms when they are first used and to develop each new concept in a logical progression. Larger pieces, like recursion and object-oriented programming are divided into a sequence of smaller steps and introduced over the course of several chapters.\" Uses Python 2.",
            "tags": [
                "Python Textbooks",
                "Beginner Python"
            ],
            "title": "Think Python 1e",
            "url": "http://greenteapress.com/wp/think-python/"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Stats is an introduction to Probability and Statistics for Python programmers. Think Stats emphasizes simple techniques you can use to explore real data sets and answer interesting questions. The book presents a case study using data from the National Institutes of Health. Readers are encouraged to work on a project with real datasets. If you have basic skills in Python, you can use them to learn concepts in probability and statistics. Think Stats is based on a Python library for probability distributions (PMFs and CDFs). Many of the exercises use short programs to run experiments and help readers develop understanding.\"",
            "tags": [
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Think Stats 2e",
            "url": "http://greenteapress.com/thinkstats2/index.html"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Bayes is an introduction to Bayesian statistics using computational methods. Most books on Bayesian statistics use mathematical notation and present ideas in terms of mathematical concepts like calculus. This book uses Python code instead of math, and discrete approximations instead of continuous mathematics. As a result, what would be an integral in a math book becomes a summation, and most operations on probability distributions are simple loops.\"",
            "tags": [
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Think Bayes",
            "url": "http://greenteapress.com/wp/think-bayes/"
        },
        {
            "author": "Allen Downey",
            "description": "\"This book is about complexity science, data structures and algorithms, intermediate programming in Python, and the philosophy of science.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Think Complexity",
            "url": "http://greenteapress.com/complexity/index.html"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think DSP is an introduction to Digital Signal Processing in Python.\"",
            "tags": [
                "Statistics Textbooks"
            ],
            "title": "Think DSP",
            "url": "http://greenteapress.com/wp/think-dsp/"
        },
        {
            "author": "Gary W. Oehlert",
            "description": "\"This text covers the basic topics in experimental design and analysis and is intended for graduate students and advanced undergraduates. Students should have had an introductory statistical methods course at about the level of Moore and McCabe's Introduction to the Practice of Statistics (Moore and McCabe 1999) and be familiar with t-tests, p-values, confidence intervals, and the basics of regression and ANOVA.\"",
            "tags": [
                "Statistics Textbooks"
            ],
            "title": "A First Course in Design and Analysis of Experiments",
            "url": "http://users.stat.umn.edu/~gary/book/fcdae.pdf"
        },
        {
            "author": "David J.C. MacKay",
            "description": "\"This book is aimed at senior undergraduates and graduate students in Engineering, Science, Mathematics, and Computing. It expects familiarity with calculus, probability theory, and linear algebra as taught in a first- or secondyear undergraduate course on mathematics for scientists and engineers. Conventional courses on information theory cover not only the beautiful theoretical ideas of Shannon, but also practical solutions to communication problems. This book goes further, bringing in Bayesian data modelling, Monte Carlo methods, variational methods, clustering algorithms, and neural networks.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks"
            ],
            "title": "Information Theory, Inference, and Learning Algorithms",
            "url": "http://www.inference.phy.cam.ac.uk/itila/"
        },
        {
            "author": "Jure Leskovec, Anand Rajaraman, Jeff Ullman (Stanford University)",
            "description": "\"The book is based on Stanford Computer Science course CS246: Mining Massive Datasets (and CS345A: Data Mining). The book, like the course, is designed at the undergraduate computer science level with no formal prerequisites. To support deeper explorations, most of the chapters are supplemented with further reading references.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Mining Massive Datasets",
            "url": "http://www.mmds.org/#ver21"
        },
        {
            "author": "Carl Edward Rasmussen and Christopher K. I. Williams",
            "description": "\"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "url": "http://www.gaussianprocess.org/gpml/"
        },
        {
            "author": "Max Welling",
            "description": "A nice introduction to various algorithms, with intuitive explanations of the formulas.",
            "tags": [
                "Machine Learning Textbooks",
                "Beginner Machine Learning"
            ],
            "title": "A First Encounter with Machine Learning",
            "url": "https://www.ics.uci.edu/~welling/teaching/ICS273Afall11/IntroMLBook.pdf"
        },
        {
            "author": "David Barber",
            "description": "\"The book is designed to appeal to students with only a modest mathematical background in undergraduate calculus and linear algebra. No formal computer science or statistical background is required to follow the book, although a basic familiarity with probability, calculus and linear algebra would be useful. The book should appeal to students from a variety of backgrounds, including Computer Science, Engineering, applied Statistics, Physics, and Bioinformatics that wish to gain an entry to probabilistic approaches in Machine Learning. In order to engage with students, the book introduces fundamental concepts in inference using only minimal reference to algebra and calculus. More mathematical techniques are postponed until as and when required, always with the concept as primary and the mathematics secondary.\"",
            "tags": [
                "Machine Learning Textbooks",
                "Statistics Textbooks"
            ],
            "title": "Bayesian Reasoning and Machine Learning",
            "url": "http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online"
        },
        {
            "author": "Richard S. Sutton and Andrew G. Barto",
            "description": "\"The book consists of three parts. Part I is introductory and problem oriented. We focus on the simplest aspects of reinforcement learning and on its main distinguishing features. One full chapter is devoted to introducing the reinforcement learning problem whose solution we explore in the rest of the book. Part II presents what we see as the three most important elementary solution methods: dynamic programming, simple Monte Carlo methods, and temporal-difference learning. The first of these is a planning method and assumes explicit knowledge of all aspects of a problem, whereas the other two are learning methods. Part III is concerned with generalizing these methods and blending them. Eligibility traces allow unification of Monte Carlo and temporal-difference methods, and function approximation methods such as artificial neural networks extend all the methods so that they can be applied to much larger problems. We bring planning and learning methods together again and relate them to heuristic search. Finally, we summarize our view of the state of reinforcement learning research and briefly present case studies, including some of the most impressive applications of reinforcement learning to date.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Reinforcement Learning: An Introduction ",
            "url": "http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html"
        },
        {
            "author": "Cosma Rohilla Shalizi",
            "description": "\"This book began as the notes for 36-402, Advanced Data Analysis, at Carnegie Mellon University... ADA is a class in statistical methodology: its aim is to get students to understand something of the range of modern methods of data analysis, and of the considerations which go into choosing the right method for the job at hand (rather than distorting the problem to fit the methods you happen to know). Statistical theory is kept to a minimum, and largely introduced as needed. Since ADA is also a class in data analysis, there are a lot of assignments in which large, real data sets are analyzed with the new methods.\"",
            "tags": [
                "Statistics Textbooks",
                "R Textbooks"
            ],
            "title": "Advanced Data Analysis from an Elementary Point of View",
            "url": "http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/"
        },
        {
            "author": "Hans Fangohr",
            "description": "\"This text summarises a number of core ideas relevant to Computational Engineering and Scientific Computing using Python. The emphasis is on introducing some basic Python (programming) concepts that are relevant for numerical algorithms. The later chapters touch upon numerical libraries such as `numpy` and `scipy` each of which deserves much more space than provided here. We aim to enable the reader to learn independently how to use other functionality of these libraries using the available documentation (online and through the packages itself).\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Python for Computational Science and Engineering (book)",
            "url": "http://www.southampton.ac.uk/~fangohr/teaching/python/book.html"
        },
        {
            "author": "Muhammad Yasoob Ullah Khalid",
            "description": "\"The topics which are discussed in this book open up your mind towards some nice corners of Python language. This book is an outcome of my desire to have something like this when I was beginning to learn Python.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Intermediate Python",
            "url": "http://book.pythontips.com/en/latest/"
        },
        {
            "author": "Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani",
            "description": "\"This book provides an introduction to statistical learning methods. It is aimed for upper level undergraduate students, masters students and Ph.D. students in the non-mathematical sciences. The book also contains a number of R labs with detailed explanations on how to implement the various methods in real life settings, and should be a valuable resource for a practicing data scientist.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks",
                "R Textbooks",
                "Beginner Machine Learning"
            ],
            "title": "An Introduction to Statistical Learning",
            "url": "http://www-bcf.usc.edu/~gareth/ISL/"
        },
        {
            "author": "Trevor Hastie, Robert Tibshirani, Jerome Friedman",
            "description": "\"During the past decade has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book descibes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks",
                "R Textbooks"
            ],
            "title": "The Elements of Statistical Learning",
            "url": "http://statweb.stanford.edu/~tibs/ElemStatLearn/"
        },
        {
            "author": "Zico Kolter (updated by Chuong Do)",
            "description": "A concise overview of linear algebra.",
            "tags": [
                "Math Textbooks"
            ],
            "title": "Linear Algebra Review and Reference",
            "url": "https://www.cs.cmu.edu/~15381/slides/linalg_notes.pdf"
        },
        {
            "author": "Roger Levy",
            "description": "\"I'm in the process of writing a textbook on the topic of using probabilistic models in scientific work on language ranging from experimental data analysis to corpus work to cognitive modeling. The intended audience is graduate students in linguistics, psychology, cognitive science, and computer science who are interested in using probabilistic models to study language.\"",
            "tags": [
                "R Textbooks",
                "Statistics Textbooks"
            ],
            "title": "Probabilistic Models in the Study of Language",
            "url": "http://idiom.ucsd.edu/~rlevy/pmsl_textbook/text.html"
        },
        {
            "author": "Hadley Wickham and Garrett Grolemund",
            "description": "\"This book will teach you how to do data science with R: You\u2019ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you\u2019ll learn how to clean data and draw plots\u2014and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You\u2019ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You\u2019ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.\"",
            "tags": [
                "R Textbooks",
                "Visualization Textbooks"
            ],
            "title": "R for Data Science",
            "url": "http://r4ds.had.co.nz/index.html"
        },
        {
            "author": "Ani Adhikari and John DeNero",
            "description": "\"Data are descriptions of the world around us, collected through observation and stored on computers. Computers enable us to infer properties of the world from these descriptions. Data science is the discipline of drawing conclusions from data using computation. There are three core aspects of effective data analysis: exploration, prediction, and inference. This text develops a consistent approach to all three, introducing statistical ideas and fundamental ideas in computer science concurrently. We focus on a minimal set of core techniques that they apply to a vast range of real-world applications. A foundation in data science requires not only understanding statistical and computational techniques, but also recognizing how they apply to real scenarios.\" Uses Python 3.",
            "tags": [
                "Python Textbooks",
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Computational and Inferential Thinking",
            "url": "http://www.inferentialthinking.com/"
        },
        {
            "author": "Avrim Blum, John Hopcroft and Ravindran Kannan",
            "description": "\"This book starts with the treatment of high dimensional geometry... We focus on singular value decomposition, a central tool in this area... Central to our understanding of large structures, like the web and social networks, is building models to capture essential properties of these structures... We describe the foundations of machine learning, both algorithms for optimizing over given training examples, as well as the theory for understanding when such optimization can be expected to lead to good performance on new, unseen data... In Chapter 7 we study how to draw good samples efficiently and how to estimate statistical and linear algebra quantities, with such samples... After describing some of the basic methods for clustering, such as the k-means algorithm, we focus on modern developments in understanding these, as well as newer algorithms.  This book also covers graphical models and belief propagation, ranking and voting, sparse vectors, and compressed sensing. The appendix includes a wealth of background material.",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Foundations of Data Science",
            "url": "https://www.cs.cornell.edu/jeh/book2016June9.pdf"
        },
        {
            "author": "Cam Davidson-Pilon",
            "description": "\"Bayesian Methods for Hackers is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical-background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.\"",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Probabilistic Programming and Bayesian Methods for Hackers",
            "url": "https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers"
        },
        {
            "author": "Robert Ghrist and David Lonoff",
            "description": "Wiki of Calculus topics",
            "tags": [
                "Math Textbooks"
            ],
            "title": "The PennCalcWiki",
            "url": "http://calculus.seas.upenn.edu/"
        },
        {
            "description": "\"Simple and efficient tools for data mining and data analysis.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "scikit-learn",
            "url": "http://scikit-learn.org/stable/"
        },
        {
            "description": "Flow chart for Machine Learning Algorithms in scikit-learn.",
            "tags": [
                "Machine Learning Misc",
                "Beginner Machine Learning"
            ],
            "title": "scikit-learn algorithm cheat sheet",
            "url": "http://scikit-learn.org/stable/tutorial/machine_learning_map/"
        },
        {
            "description": "\"*pandas* is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "pandas",
            "url": "http://scikit-learn.org/stable/"
        },
        {
            "description": "\"The Blaze Ecosystem provides Python users high-level access to efficient computation on inconveniently large data. Blaze can refer to both a particular library as well as an ecosystem of related projects that have spun off of Blaze development.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "Blaze",
            "url": "https://blaze.readthedocs.io/en/latest/index.html"
        },
        {
            "description": "\"Dask is a flexible parallel computing library for analytic computing.<br>Dask is composed of two components:<br>Dynamic task scheduling optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.<br>'Big Data' collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of the dynamic task schedulers.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "Dask",
            "url": "http://dask.pydata.org/en/latest/"
        },
        {
            "description": "\"Statsmodels is a Python module that allows users to explore data, estimate statistical models, and perform statistical tests. An extensive list of descriptive statistics, statistical tests, plotting functions, and result statistics are available for different types of data and each estimator.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "Statsmodels",
            "url": "http://statsmodels.sourceforge.net/"
        },
        {
            "description": "\"NumPy is the fundamental package for scientific computing with Python. It contains among other things:  a powerful N-dimensional array object; sophisticated (broadcasting) functions; tools for integrating C/C++ and Fortran code; useful linear algebra, Fourier transform, and random number capabilities.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "NumPy",
            "url": "http://www.numpy.org/"
        },
        {
            "description": "\"It provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "SciPy",
            "url": "https://www.scipy.org/scipylib/index.html"
        },
        {
            "description": "\"matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell..., web application servers, and six graphical user interface toolkits.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "matplotlib",
            "url": "http://matplotlib.org/"
        },
        {
            "description": "\"SymPy is a Python library for symbolic mathematics. It aims to become a full-featured computer algebra system (CAS) while keeping the code as simple as possible in order to be comprehensible and easily extensible. SymPy is written entirely in Python.\"",
            "tags": [
                "Python Packages",
                "Math Packages"
            ],
            "title": "SymPy",
            "url": "http://www.sympy.org/en/index.html"
        },
        {
            "description": "\"Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "Seaborn",
            "url": "https://web.stanford.edu/~mwaskom/software/seaborn/"
        },
        {
            "description": "\"Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. Its goal is to provide elegant, concise construction of novel graphics in the style of D3.js, and to extend this capability with high-performance interactivity over very large or streaming datasets. Bokeh can help anyone who would like to quickly and easily create interactive plots, dashboards, and data applications.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "Bokeh",
            "url": "http://bokeh.pydata.org/en/latest/"
        },
        {
            "description": "\"ggplot is a plotting system for Python based on R's ggplot2 and the Grammar of Graphics. It is built for making profressional looking, plots quickly with minimal code.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "ggplot",
            "url": "http://ggplot.yhathq.com/"
        },
        {
            "description": "\"TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization. The system is designed to facilitate research in machine learning, and to make it quick and easy to transition from research prototype to production system.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "TensorFlow",
            "url": "https://www.tensorflow.org/"
        },
        {
            "description": "\"OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms. It makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. You can use it from Python code, and soon from other languages.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "gym",
            "url": "https://gym.openai.com/docs"
        },
        {
            "description": "\"a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites and other applications.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "universe",
            "url": "https://github.com/openai/universe"
        },
        {
            "description": "\"PyMC3 is a python module for Bayesian statistical modeling and model fitting which focuses on advanced Markov chain Monte Carlo fitting algorithms. Its flexibility and extensibility make it applicable to a large suite of problems.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "PyMC3",
            "url": "http://pymc-devs.github.io/pymc3/"
        },
        {
            "description": "\"PyStan provides an interface to Stan, a package for Bayesian inference using the No-U-Turn sampler, a variant of Hamiltonian Monte Carlo.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "PyStan",
            "url": "https://pystan.readthedocs.io/en/latest/"
        },
        {
            "description": "\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "NLTK",
            "url": "http://www.nltk.org/"
        },
        {
            "description": "\"spaCy helps you write programs that do clever things with text. You give it a string of characters, it gives you an object that provides multiple useful views of its meaning and linguistic structure. Specifically, spaCy features a high performance tokenizer, part-of-speech tagger, named entity recognizer and syntactic dependency parser, with built-in support for word vectors. All of the functionality is united behind a clean high-level Python API, that makes it easy to use the different annotations together.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "spaCy",
            "url": "https://spacy.io/"
        },
        {
            "description": "topic modelling for humans",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "gensim",
            "url": "http://radimrehurek.com/gensim/index.html"
        },
        {
            "description": "\"Fuzzy string matching like a boss. It uses Levenshtein Distance to calculate the differences between sequences in a simple-to-use package.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "FuzzyWuzzy",
            "url": "https://github.com/seatgeek/fuzzywuzzy"
        },
        {
            "description": "\"OpenCV is released under a BSD license and hence it\u2019s free for both academic and commercial use. It has C++, C, Python and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV was designed for computational efficiency and with a strong focus on real-time applications.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "OpenCV-Python",
            "url": "http://opencv.org/"
        },
        {
            "description": "\"SimpleCV is an open source framework for building computer vision applications. With it, you get access to several high-powered computer vision libraries such as OpenCV \u2013 without having to first learn about bit depths, file formats, color spaces, buffer management, eigenvalues, or matrix versus bitmap storage. This is computer vision made easy.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "Simple CV",
            "url": "http://simplecv.org/"
        },
        {
            "description": "\"scikit-image is a collection of algorithms for image processing. It is available free of charge and free of restriction. We pride ourselves on high-quality, peer-reviewed code, written by an active community of volunteers.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "scikit-image",
            "url": "http://scikit-image.org/"
        },
        {
            "description": "\"Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "Theano",
            "url": "http://deeplearning.net/software/theano/"
        },
        {
            "description": "\"Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "Keras",
            "url": "http://keras.io/"
        },
        {
            "description": "An optimized, flexible, portable, regression and classification gradient boosting package that supports distributed training.",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "XGBoost (Python)",
            "url": "http://xgboost.readthedocs.io/en/latest/python/python_intro.html"
        },
        {
            "description": "\"tsfresh is a python package that is used to automatically calculate a huge number of time series characteristics, the so called features. Further the package contains methods to evaluate the explaining power and importance of such characteristics for regression or classification tasks.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "tsfresh",
            "url": "http://tsfresh.readthedocs.io/en/latest/"
        },
        {
            "description": "\"lifelines is a implementation of survival analysis in Python,\" built on top of pandas",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "Lifelines",
            "url": "https://lifelines.readthedocs.io/en/latest/"
        },
        {
            "description": "An optimized, flexible, portable, regression and classification gradient boosting package that supports distributed training.",
            "tags": [
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "XGBoost (R)",
            "url": "http://xgboost.readthedocs.io/en/latest/R-package/index.html"
        },
        {
            "description": "\"Airflow is a platform to programmatically author, schedule and monitor workflows.<br>When workflows are defined as code, they become more maintainable, versionable, testable, and collaborative.<br>Use Airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The Airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "airflow",
            "url": "http://pythonhosted.org/airflow/"
        },
        {
            "description": "\"Luigi is a Python (2.7, 3.3, 3.4, 3.5) package that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "luigi",
            "url": "https://luigi.readthedocs.io/en/stable/"
        },
        {
            "description": "\"The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for:  data splitting; pre-processing; feature selection; model tuning using resampling; variable importance estimation.\"",
            "tags": [
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "caret",
            "url": "http://topepo.github.io/caret/index.html"
        },
        {
            "description": "\"A data.frame processor/conditioner that prepares real-world data for predictive modeling in a statistically sound manner. Prepares variables so that data has fewer exceptional cases, making it easier to safely use models in production. Common problems 'vtreat' defends against: Inf, NA, too many categorical levels, rare categorical levels, new categorical levels (levels seen during application, but not during training).\"",
            "tags": [
                "R Packages",
                "Statistics Packages"
            ],
            "title": "vtreat",
            "url": "https://cran.r-project.org/web/packages/vtreat/index.html"
        },
        {
            "description": "\"A powerful and elegant high-level data visualization system inspired by Trellis graphics, with an emphasis on multivariate data. Lattice is sufficient for typical graphics needs, and is also flexible enough to handle most nonstandard requirements. See ?Lattice for an introduction.\"",
            "tags": [
                "R Packages",
                "Visualization Packages"
            ],
            "title": "Lattice",
            "url": "https://cran.r-project.org/web/packages/lattice/index.html"
        },
        {
            "description": "\"ggplot2 is a plotting system for R, based on the grammar of graphics, which tries to take the good parts of base and lattice graphics and none of the bad parts. It takes care of many of the fiddly details that make plotting a hassle (like drawing legends) as well as providing a powerful model of graphics that makes it easy to produce complex multi-layered graphics.\"",
            "tags": [
                "R Packages",
                "Visualization Packages"
            ],
            "title": "ggplot2",
            "url": "http://ggplot2.org/"
        },
        {
            "description": "\"Functions and datasets to support Venables and Ripley, 'Modern Applied Statistics with S' (4th edition, 2002).\"",
            "tags": [
                "R Packages",
                "Statistics Packages"
            ],
            "title": "MASS",
            "url": "https://cran.r-project.org/web/packages/MASS/index.html"
        },
        {
            "description": "\"A set of tools that solves a common set of problems: you need to break a big problem down into manageable pieces, operate on each piece and then put all the pieces back together. For example, you might want to fit a model to each spatial location or time point in your study, summarise data by panels or collapse high-dimensional arrays to simpler summary statistics. The development of 'plyr' has been generously supported by 'Becton Dickinson'.\"",
            "tags": [
                "R Packages"
            ],
            "title": "plyr",
            "url": "https://cran.r-project.org/web/packages/plyr/index.html"
        },
        {
            "description": "\"A fast, consistent tool for working with data frame like objects, both in memory and out of memory.\"",
            "tags": [
                "R Packages"
            ],
            "title": "dplyr",
            "url": "https://cran.r-project.org/web/packages/dplyr/index.html"
        },
        {
            "description": "\"Flexibly restructure and aggregate data using just two functions: melt and dcast (or acast).\"",
            "tags": [
                "R Packages"
            ],
            "title": "reshape2",
            "url": "https://cran.r-project.org/web/packages/reshape2/index.html"
        },
        {
            "author": "Charles Severance (with material adapted from Allen Downey)",
            "description": "\"The goal of this book is to provide an Informatics-oriented introduction to programming. The primary difference between a computer science approach and the Informatics approach taken in this book is a greater focus on using Python to solve data analysis problems common in the world of Informatics.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Python for Informatics: Exploring Information",
            "url": "http://www.pythonlearn.com/book.php"
        },
        {
            "author": "Tom Augspurger",
            "description": "\"This series is about how to make effective use of pandas, a data analysis library for the Python programming language. It's targeted at an intermediate level: people who have some experince with pandas, but are looking to improve.\" Based on series of posts found here: <a href='http://tomaugspurger.github.io/modern-1.html'>http://tomaugspurger.github.io/modern-1.html</a> Payment optional.",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Effective Pandas",
            "url": "https://leanpub.com/effective-pandas"
        },
        {
            "author": "Andrew Ng, Stanford University",
            "description": "\"This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.\"",
            "tags": [
                "Machine Learning Courses",
                "Beginner Machine Learning"
            ],
            "title": "Machine Learning",
            "url": "https://www.coursera.org/learn/machine-learning"
        },
        {
            "author": "Geoffrey Hinton",
            "description": "\"Learn about artificial neural networks and how they're being used for machine learning, as applied to speech and object recognition, image segmentation, modeling language and human motion, etc. We'll emphasize both the basic algorithms and the practical tricks needed to get them to work well.<br>This course contains the same content presented on Coursera beginning in 2013. It is not a continuation or update of the original course. It has been adapted for the new platform.<br>Please be advised that the course is suited for an intermediate level learner - comfortable with calculus and with experience programming (Python).\"",
            "tags": [
                "Machine Learning Courses"
            ],
            "title": "Neural Networks for Machine Learning",
            "url": "https://www.coursera.org/learn/neural-networks"
        },
        {
            "author": "Jeremy Howard",
            "description": "\"Learn how to build state of the art models without needing graduate-level math\u2014but also without dumbing anything down.\"",
            "tags": [
                "Machine Learning Courses"
            ],
            "title": "Practical Deep Learning for Coders, Part 1",
            "url": "http://course.fast.ai/"
        },
        {
            "author": "IBM",
            "description": "\"In this learning path, you will be able to learn the basic concepts of Neural Networks, Deep Leaning and TensorFlow. Then, you will get hands-on experience in solving problems using Deep Learning. Starting with a simple \u201cHello Word\u201d example, throughout the course you will be able to see how TensorFlow can be used in curve fitting, regression, classification and minimization of error functions. This concept is then explored in the Deep Learning world. You will learn how to apply TensorFlow for backpropagation to tune the weights and biases while the Neural Networks are being trained. Finally, the course covers different types of Deep Architectures, such as Convolutional Networks, Recurrent Networks and Autoencoders.\"",
            "tags": [
                "Machine Learning Courses"
            ],
            "title": "Deep Learning Learning Path from Big Data University",
            "url": "https://bigdatauniversity.com/learn/deep-learning/"
        },
        {
            "author": "Yaser S. Abu-Mostafa (Caltech)",
            "description": "\"Introductory Machine Learning course covering theory, algorithms and applications. Our focus is on real understanding, not just 'knowing.'\"",
            "tags": [
                "Machine Learning Courses",
                "Beginner Machine Learning"
            ],
            "title": "Learning From Data (Introductory Machine Learning)",
            "url": "https://www.edx.org/course/learning-data-introductory-machine-caltechx-cs1156x"
        },
        {
            "author": "Jim Fowler, The Ohio State University",
            "description": "\"This course is a first and friendly introduction to calculus, suitable for someone who has never seen the subject before, or for someone who has seen some calculus but wants to review the concepts and practice applying those concepts to solve problems.\"",
            "tags": [
                "Math Courses"
            ],
            "title": "Calculus One",
            "url": "https://www.coursera.org/learn/calculus1"
        },
        {
            "author": "Gilbert Strang",
            "description": "MIT's Linear Algebra course.  Full materials available <a href='https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/'>here<a>.",
            "tags": [
                "Math Courses"
            ],
            "title": "MIT 18.06 Linear Algebra, Spring 2005",
            "url": "https://www.youtube.com/watch?v=ZK3O402wf1c&list=PLE7DDD91010BC51F8"
        },
        {
            "author": "Daphne Koller, Stanford University",
            "description": "\"In this class, you will learn the basics of the PGM representation and how to construct them, using both human knowledge and machine learning techniques; you will also learn algorithms for using a PGM to reach conclusions about the world from limited and noisy evidence, and for making good decisions under uncertainty. The class covers both the theoretical underpinnings of the PGM framework and practical skills needed to apply these techniques to new problems.\"  Sign up for a previous offering of the course.",
            "tags": [
                "Machine Learning Courses"
            ],
            "title": "Probabilistic Graphical Models",
            "url": "https://www.coursera.org/learn/probabilistic-graphical-models"
        },
        {
            "author": "Eric Grimson, John Guttag, and Ana Bell (MIT)",
            "description": "\"What you'll learn: A Notion of computation, The Python programming language, Some simple algorithms, Testing and debugging, An informal introduction to algorithmic complexity, Data structures\"",
            "tags": [
                "Python Courses",
                "Beginner Python"
            ],
            "title": "Introduction to Computer Science and Programming Using Python",
            "url": "https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x8"
        },
        {
            "author": "Eric Grimson, John Guttag, and Ana Bell, MIT",
            "description": "\"6.00.2x will teach you how to use computation to accomplish a variety of goals and provides you with a brief introduction to a variety of topics in computational problem solving . This course is aimed at students with some prior programming experience in Python and a rudimentary knowledge of computational complexity. You will spend a considerable amount of time writing programs to implement the concepts covered in the course. For example, you will write a program that will simulate a robot vacuum cleaning a room or will model the population dynamics of viruses replicating and drug treatments in a patient's body.\"",
            "tags": [
                "Python Courses"
            ],
            "title": "Introduction to Computational Thinking and Data Science",
            "url": "https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-3"
        },
        {
            "author": "Filip Schouwenaars, Microsoft",
            "description": "\"In this practical course, you will start from the very beginning, with basic arithmetic and variables, and learn how to handle data structures, such as Python lists, Numpy arrays, and Pandas DataFrames. Along the way, you'll learn about Python functions and control flow. Plus, you'll look at the world of data visualizations with Python and create your own stunning visualizations based on real data.\"",
            "tags": [
                "Python Courses",
                "Beginner Python"
            ],
            "title": "Introduction to Python for Data Science",
            "url": "https://www.edx.org/course/introduction-python-data-science-microsoft-dat208x-4"
        },
        {
            "author": "Authman Apatira, Microsoft",
            "description": "\"In this practical computer science course, you will build on your existing Python skills and learn how to manipulate data using Pandas, and build machine learning solutions in Python using the scikit-learn package.\"",
            "tags": [
                "Python Courses",
                "Machine Learning Courses"
            ],
            "title": "Programming with Python for Data Science",
            "url": "https://www.edx.org/course/programming-python-data-science-microsoft-dat210x-2"
        },
        {
            "author": "Filip Schouwenaars, Microsoft",
            "description": "\"This introduction to R programming course will help you master the basics of R. In seven sections, you will cover its basic syntax, making you ready to undertake your own first data analysis using R. Starting from variables and basic operations, you will eventually learn how to handle data structures such as vectors, matrices, data frames and lists. In the final section, you will dive deeper into the graphical capabilities of R, and create your own stunning data visualizations. No prior knowledge in programming or data science is required.\"",
            "tags": [
                "R Courses",
                "Beginner R"
            ],
            "title": "Introduction to R for Data Science",
            "url": "https://www.edx.org/course/introduction-r-data-science--2microsoft-dat204x-3"
        },
        {
            "author": "Anders Stockmarr",
            "description": "\"In this course you will learn all you need to get up to speed with programming in R. Explore R data structures and syntaxes, see how to read and write data from a local file to a cloud-hosted database, work with data, get summaries, and transform them to fit your needs. Plus, find out how to perform predictive analytics using R and how to create visualizations using the popular ggplot2 package.\"",
            "tags": [
                "R Courses",
                "Machine Learning Courses"
            ],
            "title": "Programming with R for Data Science",
            "url": "https://www.edx.org/course/programming-r-data-science-microsoft-dat209x-2"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course will teach you the basics of working with Spark and will provide you with the necessary foundation for diving deeper into Spark. You'll learn about Spark's architecture and programming model, including commonly used APIs. After completing this course, you'll be able to write and debug basic Spark applications. This course will also explain how to use Spark's web user interface (UI), how to recognize common coding errors, and how to proactively prevent errors. The focus of this course will be Spark Core and Spark SQL.\"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Introduction to Apache Spark",
            "url": "https://www.edx.org/course/introduction-apache-spark-uc-berkeleyx-cs105x"
        },
        {
            "author": "Ameet Talwalkar, UCLA and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course introduces the underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines. We present an integrated view of data processing by highlighting the various components of these pipelines, including exploratory data analysis, feature extraction, supervised learning, and model evaluation. You will gain hands-on experience applying these principles using Spark, a cluster computing system well-suited for large-scale machine learning tasks, and its packages spark.ml and spark.mllib. You will implement distributed algorithms for fundamental statistical models (linear regression, logistic regression, principal component analysis) while tackling key problems from domains such as online advertising and cognitive neuroscience.\"",
            "tags": [
                "Spark Courses",
                "Machine Learning Courses"
            ],
            "title": "Distributed Machine Learning with Apache Spark",
            "url": "https://www.edx.org/course/distributed-machine-learning-apache-uc-berkeleyx-cs120x"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course will attempt to articulate the expected output of data scientists and then teach students how to use PySpark (part of Spark) to deliver against these expectations. The course assignments include log mining, textual entity recognition, and collaborative filtering exercises that teach students how to manipulate data sets using parallel processing with PySpark.\"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Big Data Analysis with Apache Spark",
            "url": "https://www.edx.org/course/big-data-analysis-apache-spark-uc-berkeleyx-cs110x"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"Gain a deeper understanding of Spark by learning about its APIs, architecture, and common use cases.  This statistics and data analysis course will cover material relevant to both data engineers and data scientists.  You'll learn how Spark efficiently transfers data across the network via its shuffle, details of memory management, optimizations to reduce compute costs, and more.  Learners will see several use cases for Spark and will work to solve a variety of real-world problems using public datasets.  After taking this course, you should have a thorough understanding of how Spark works and how you can best utilize its APIs to write efficient, scalable code.  You'll also learn about a wide variety of Spark's APIs, including the APIs in Spark Streaming. \"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Advanced Apache Spark for Data Science and Data Engineering",
            "url": "https://www.edx.org/course/advanced-apache-spark-data-science-data-uc-berkeleyx-cs115x"
        },
        {
            "author": "Ameet Talwalkar, UCLA and Jon Bates, Databricks",
            "description": "\"Building on the core ideas presented in Distributed Machine Learning with Spark, this course covers advanced topics for training and deploying large-scale learning pipelines. You will study state-of-the-art distributed algorithms for collaborative filtering, ensemble methods (e.g., random forests), clustering and topic modeling, with a focus on model parallelism and the crucial tradeoffs between computation and communication.\"",
            "tags": [
                "Spark Courses",
                "Machine Learning Courses"
            ],
            "title": "Advanced Distributed Machine Learning with Apache Spark",
            "url": "https://www.edx.org/course/advanced-distributed-machine-learning-uc-berkeleyx-cs125x"
        },
        {
            "author": "Trevor Hastie and Rob Tibshirani, Stanford University",
            "description": "\"This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).\"",
            "tags": [
                "Statistics Courses",
                "Machine Learning Courses",
                "R Courses"
            ],
            "title": "Statistical Learning",
            "url": "http://online.stanford.edu/course/statistical-learning-Winter-16"
        },
        {
            "author": "David Robinson and Neo Christopher Chung (Princeton University)",
            "description": "\"This course combines video, HTML and interactive components to teach the statistical programming language R.\"",
            "tags": [
                "R Courses",
                "Beginner R"
            ],
            "title": "Data Analysis and Visualization Using R",
            "url": "http://varianceexplained.org/RData/"
        },
        {
            "author": "Brian Caffo, Johns Hopkins University",
            "description": "\"This class presents the fundamental probability and statistical concepts used in elementary data analysis. It will be taught at an introductory level for students with junior or senior college-level mathematical training including a working knowledge of calculus. A small amount of linear algebra and programming are useful for the class, but not required.\"Part I: <a href='https://www.coursera.org/learn/biostatistics'>Mathematical Biostatistics Boot Camp</a><br>Part II: <a href='https://www.coursera.org/learn/biostatistics-2'>Mathematical Biostatistics Boot Camp 2</a>",
            "tags": [
                "Statistics Courses"
            ],
            "title": "Mathematical Biostatistics Boot Camp",
            "url": "https://www.coursera.org/learn/biostatistics"
        },
        {
            "author": "mathematicalmonk",
            "description": "160 Machine Learning Short Lectures",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "Machine Learning Playlist",
            "url": "https://www.youtube.com/user/mathematicalmonk/playlists"
        },
        {
            "author": "Yaser Abu-Mostafa (Caltech)",
            "description": "Machine Learning course from Caltech. \"The fundamental concepts and techniques are explained in detail. The focus of the lectures is real understanding, not just 'knowing.'\"",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "Learning From Data",
            "url": "http://work.caltech.edu/lectures.html"
        },
        {
            "author": "Stanford University",
            "description": "\"This course is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification.\" Course includes a <a href='http://cs231n.github.io/python-numpy-tutorial/'>Python tutorial.</a>  Uses Python 2.",
            "tags": [
                "Machine Learning Lectures",
                "Tutorials in Python"
            ],
            "title": "CS231n: Convolutional Neural Networks for Visual Recognition",
            "url": "http://cs231n.stanford.edu/"
        },
        {
            "author": "Joe Blitzstein, Hanspeter Pfister, Verena Kaynig-Fittkau (Harvard University)",
            "description": "Lectures from Harvard Extension School's Data Science class",
            "tags": [
                "Machine Learning Lectures",
                "Python Lectures"
            ],
            "title": "Data Science",
            "url": "http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml"
        },
        {
            "author": "mathematicalmonk",
            "description": "43 Short Probability Lectures",
            "tags": [
                "Probability Lectures"
            ],
            "title": "Probabilty Playlist",
            "url": "https://www.youtube.com/watch?v=Tk4ubu7BlSk&list=PL17567A1A3F5DB5E4"
        },
        {
            "author": "mathematicalmonk",
            "description": "54 Short Information Theory Lectures",
            "tags": [
                "Information Theory Lectures"
            ],
            "title": "Information Theory Playlist",
            "url": "https://www.youtube.com/watch?v=UrefKMSEuAI&list=PLE125425EC837021F"
        },
        {
            "author": "Thomas M. Cover",
            "description": "\"This book has arisen from over ten years of lectures in a two-quarter sequence of a senior and first-year graduate-level course in information theory, and is intended as an introduction to information theory for students of communication theory, computer science, and statistics.\"",
            "tags": [
                "Information Theory Textbooks"
            ],
            "title": "Elements of Information Theory",
            "url": "http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf"
        },
        {
            "author": "Andrew Gelman",
            "description": "This is a blog by the author of Bayesian Data Analysis.",
            "tags": [
                "Statistics Blogs"
            ],
            "title": "Statistical Modeling, Causal Inference, and Social Science",
            "url": "http://andrewgelman.com/"
        },
        {
            "author": "John D. Cook",
            "description": "A blog about applied math, statistics, and software development.",
            "tags": [
                "Statistics Blogs",
                "Programming Blogs"
            ],
            "title": "John D. Cook",
            "url": "http://www.johndcook.com/blog/"
        },
        {
            "author": "Michael Kennedy",
            "description": "\"The show covers a wide array of Python topics as well as many related topics (e.g. MongoDB, AngularJS, DevOps).\"",
            "tags": [
                "Python Podcasts"
            ],
            "title": "Talk Python to Me",
            "url": "https://talkpython.fm/"
        },
        {
            "author": "Tobias Macey and Chris Patti",
            "description": "\"Podcast.init is a show about the Python programming language and the awesome community that has grown up around it. Our goal is to share discussions on subjects ranging from interesting and useful tools and products to social and ethical issues such as diversity and inclusiveness in tech.\"",
            "tags": [
                "Python Podcasts"
            ],
            "title": "Podcast.\\_\\_init\\_\\_",
            "url": "http://podcastinit.com/"
        },
        {
            "author": "Katherine Gorman and Ryan Adams (Harvard University)",
            "description": "\"Talking Machines is your window into the world of machine learning. Your hosts, Katherine Gorman and Ryan Adams, bring you clear conversations with experts in the field, insightful discussions of industry news, and useful answers to your questions.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "Talking Machines",
            "url": "http://www.thetalkingmachines.com/"
        },
        {
            "author": "Jonathon Morgan, Vidya Spandana, and Chris Albon",
            "description": "\"Partially Derivative is a weekly podcast, blog, and newsletter about the data science in the world around us. We geek out on silly data stories, interview amazing people doing interesting work, and drink beer.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "Partially Derivative",
            "url": "http://partiallyderivative.com/"
        },
        {
            "author": "Roger Peng (Johns Hopkins University) and Hilary Parker",
            "description": "Podcast on Data Science, Statistics, Python, and R in academia and industry.",
            "tags": [
                "Statistics Podcasts"
            ],
            "title": "Not So Standard Deviations",
            "url": "https://soundcloud.com/nssd-podcast"
        },
        {
            "author": "Ben Lorica (O'Reilly)",
            "description": "\"The O'Reilly Data Show Podcast: Danny Bickson on recommenders, data science, and applications of machine learning.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "O'Reilly Data Show Podcast",
            "url": "https://www.oreilly.com/topics/oreilly-data-show-podcast"
        },
        {
            "author": "Nathan Yau",
            "description": "\"FlowingData explores how statisticians, designers, data scientists, and others use analysis, visualization, and exploration to understand data and ourselves.\"  Paid membership optional for visualization tutorials.",
            "tags": [
                "Visualization Blogs"
            ],
            "title": "Flowing Data",
            "url": "http://flowingdata.com/"
        },
        {
            "author": "Hadley Wickham",
            "description": "Material for Hadley Wickham's course on visualization at Rice University.",
            "tags": [
                "Visualization Misc"
            ],
            "title": "Data Visualisation",
            "url": "http://had.co.nz/stat645/"
        },
        {
            "author": "Unknown",
            "description": "Flow chart for choosing a chart type.",
            "tags": [
                "Visualization Misc",
                "Beginner Visualization"
            ],
            "title": "Choosing a Data Chart",
            "url": "http://img.labnol.org/di/data-chart-type.png"
        },
        {
            "author": "Cliburn Chan (Duke University)",
            "description": "Thorough tutorial of Python from basics through scientific stack.  Uses Python 3.",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Computational Statistics in Python",
            "url": "http://people.duke.edu/~ccc14/sta-663-2016/index.html"
        },
        {
            "author": "Randy Betancourt",
            "description": "Presentation of Python data manipulations with pandas and their SAS counterparts",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Python For SAS Users",
            "url": "http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/tree/master/"
        },
        {
            "author": "Ujjwal Karn",
            "description": "\"This repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. \"",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Machine Learning & Deep Learning Tutorials",
            "url": "https://github.com/ujjwalkarn/Machine-Learning-Tutorials"
        },
        {
            "author": "Ujjwal Karn",
            "description": "\"This repo contains a curated list of Python tutorials for Data Science, NLP and Machine Learning.\"",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Python Data Science Tutorials",
            "url": "https://github.com/ujjwalkarn/DataSciencePython"
        },
        {
            "author": "Adam Geitgey in Python",
            "description": "Series of posts demonstrating various machine learning tasks using Python.  Examples include recurrent neural networks, convoluatoinal neural networks, face recognition, language translation, and speech recognition.",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Machine Learning is Fun",
            "url": "https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.jldbrt65w"
        },
        {
            "author": "qinwf",
            "description": "A curated list of awesome R packages and tools.",
            "tags": [
                "R Packages"
            ],
            "title": "Awesome R",
            "url": "https://github.com/qinwf/awesome-R"
        },
        {
            "author": "Vinta",
            "description": "A curated list of awesome Python frameworks, libraries, software and resources.",
            "tags": [
                "Python Packages"
            ],
            "title": "Awesome Python",
            "url": "https://github.com/vinta/awesome-python"
        },
        {
            "author": "Joseph Misiti",
            "description": "A curated list of awesome machine learning frameworks, libraries and software (by language). ",
            "tags": [
                "Python Packages",
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "Awesome Machine Learning",
            "url": "https://github.com/josephmisiti/awesome-machine-learning"
        },
        {
            "author": "The R Project for Statistical Computing",
            "description": "\"The R Journal is the open access, refereed journal of the R project for statistical computing. It features short to medium length articles covering topics that might be of interest to users or developers of R, including: short introductions to R extension packages; hints for programming in R; hints for newcomers explaining aspects of R that might not be so obvious from reading the manuals and FAQs; demonstrating how a new or existing technique can be applied in an area of current interest using R, providing a fresh view of such analyses in R that is of benefit beyond the specific application.\"",
            "tags": [
                "R Packages"
            ],
            "title": "The R Journal",
            "url": "https://journal.r-project.org/"
        },
        {
            "author": "",
            "description": "A curated list of awesome TensorFlow experiments, libraries, and projects. ",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Awesome TensorFlow",
            "url": "https://github.com/jtoy/awesome-tensorflow"
        },
        {
            "author": "Carl Vogel",
            "description": "Python implementations of examples from Machine Learning for Hackers. Uses Python 2.",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Will it Python? Machine Learning for Hackers",
            "url": "https://github.com/carljv/Will_it_Python/tree/master/MLFH"
        },
        {
            "author": "Chris Burns, Christophe Combelles, Emmanuelle Gouillart, and Ga\u00ebl Varoquaux",
            "description": "\"Tutorials on the scientific Python ecosystem: a quick introduction to central tools and techniques. The different chapters each correspond to a 1 to 2 hours course with increasing level of expertise, from beginner to expert.\"",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Scipy lecture notes",
            "url": "http://www.scipy-lectures.org/"
        },
        {
            "author": "Brad Miller and David Ranum",
            "description": "Interactive version of the book How to Think Like a Computer Scientist by Jeffrey Elkner, Allen B. Downey, and Chris Meyers",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "How to Think Like a Computer Scientist: Interactive Edition",
            "url": "http://interactivepython.org/runestone/static/thinkcspy/index.html"
        },
        {
            "author": "Python Software Foundation",
            "description": "Tutorials and Documentation for Beginner, Moderate, and Advanced Users.  Available for Python 2 and 3.",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Official Python Documentation",
            "url": "https://www.python.org/doc/"
        },
        {
            "author": "Kunal Jain",
            "description": "Covers basics through predictive modeling in Python 2.",
            "tags": [
                "Tutorials in Python",
                "Beginner Python"
            ],
            "title": "A Complete Tutorial to Learn Data Science with Python from Scratch",
            "url": "http://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/"
        },
        {
            "author": "Kunal Jain",
            "description": "\"In this guide, I will use NumPy, Matplotlib, Seaborn and Pandas to perform data exploration.\" Uses Python 2.",
            "tags": [
                "Tutorials in Python"
            ],
            "title": "Ultimate guide for Data Exploration in Python using NumPy, Matplotlib and Pandas",
            "url": "http://www.analyticsvidhya.com/blog/2015/04/comprehensive-guide-data-exploration-sas-using-python-numpy-scipy-matplotlib-pandas/"
        },
        {
            "author": "Michael Nielsen",
            "description": "\"The book will teach you about: Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data; Deep learning, a powerful set of techniques for learning in neural networks.\"  Uses Python 2.",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Neural Networks and Deep Learning",
            "url": "http://neuralnetworksanddeeplearning.com/"
        },
        {
            "author": "Ian Goodfellow, Yoshua Bengio and Aaron Courville",
            "description": "\"The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.\" A pdf version appears to be available here: https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Deep Learning",
            "url": "http://www.deeplearningbook.org/"
        },
        {
            "author": "John Mount and Nina Zumel",
            "description": "The Win-Vector LLC data science blog",
            "tags": [
                "Statistics Blogs",
                "Machine Learning Blogs",
                "Programming Blogs"
            ],
            "title": "Win-Vector",
            "url": "http://www.win-vector.com/blog/"
        },
        {
            "author": "Allen Downey",
            "description": "Allen Downey's PyCon tutorial for computational statistics in Python.",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Allen Downey - Computational Statistics - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=VR52vSbHBAk"
        },
        {
            "author": "Allen Downey",
            "description": "Allen Downey's PyCon tutorial for Bayesian Statistics in Python.",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Allen Downey - Bayesian statistics made simple - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=6GV5bTCLC8g"
        },
        {
            "author": "Julia Ferraioli, Amy Unruh, Eli Bixby",
            "description": "\"Machine learning can be an intimidating subject. In this session, we'll get practical, hands-on experience with core concepts in machine learning with TensorFlow, an open source deep learning library. We\u2019ll introduce the basics of TensorFlow, including how to ingest and prepare raw data for use, run a variety of algorithms to gain insight from the data, and have some fun with visualization.\"",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Diving into Machine Learning through TensorFlow - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=GZBIPwdGtkk"
        },
        {
            "author": "Jean Francois Puget",
            "description": "Tutorial on preparing data sets using Pandas",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Tidy Data In Python",
            "url": "https://www.ibm.com/developerworks/community/blogs/jfp/entry/Tidy_Data_In_Python?lang=en"
        },
        {
            "author": "Jean-Nicholas Hould",
            "description": "Translating exmaples from Hadley Wickham's Tidy Data to Pandas",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Tidy Data in Python",
            "url": "http://www.jeannicholashould.com/tidy-data-in-python.html"
        },
        {
            "author": "Zygmunt Zaj\u0105c",
            "description": "Overview of ways to pipe in functions in Python.",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Piping in R and in Pandas",
            "url": "http://fastml.com/piping-in-r-and-in-pandas/"
        },
        {
            "author": "Robert I. Kabacoff",
            "description": "\"R is an elegant and comprehensive statistical and graphical programming language. Unfortunately, it can also have a steep learning curve. I created this website for both current R users, and experienced users of other statistical packages (e.g., SAS, SPSS, Stata) who would like to transition to R. My goal is to help you quickly access this language in your work.\"  See <a href='http://www.statmethods.net/graphs/index.html'>Basic Graphs</a> and <a href='http://www.statmethods.net/advgraphs/index.html'>Advanced Graphs</a> for visualization examples.",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "Quick-R",
            "url": "http://www.statmethods.net/"
        },
        {
            "author": "Hadley Wickham",
            "description": "\"A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.\"",
            "tags": [
                "R Tutorials"
            ],
            "title": "Tidy Data",
            "url": "http://vita.had.co.nz/papers/tidy-data.pdf"
        },
        {
            "author": "Aarshay Jain",
            "description": "\"This article focuses on providing 12 ways for data manipulation in Python. I've also shared some tips & tricks which will allow you to work faster.\"",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "12 Useful Pandas Techniques in Python for Data Manipulation",
            "url": "http://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/"
        },
        {
            "author": "Skipper Seabold",
            "description": "Example of using Pandas and scikit-learn to classify whether a person makes over 50K a year.",
            "tags": [
                "Python Pandas Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Using pandas and scikit-learn for classification tasks",
            "url": "https://github.com/jseabold/depy/blob/master/pandas_sklearn_rendered.ipynb"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"This is just a small but growing collection of pandas snippets that I find occasionally and particularly useful\"",
            "tags": [
                "Tutorials in Python"
            ],
            "title": "Things in Pandas I Wish I'd Known Earlier",
            "url": "http://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/things_in_pandas.ipynb"
        },
        {
            "author": "Chris Moffitt",
            "description": "\"This article will focus on explaining the pandas pivot_table function and how to use it for your data analysis.\"",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Pandas Pivot Table Explained",
            "url": "http://pbpython.com/pandas-pivot-table-explained.html"
        },
        {
            "author": "Philipp Rudiger",
            "description": "\"In this notebook we'll look at interfacing between the composability and ability to generate complex visualizations that HoloViews provides and the great looking plots incorporated in the seaborn library. Along the way we'll explore how to wrap different types of data in a number of Seaborn View types, including: Distribution Views, Bivariate Views, TimeSeries Views\"",
            "tags": [
                "Tutorials in Python",
                "Visualization Tutorials"
            ],
            "title": "Exploring Seaborn and Pandas based plot types in HoloViews",
            "url": "http://philippjfr.com/blog/seabornviews/"
        },
        {
            "author": "yhat",
            "description": "\"This is a post about pandasql, a library we're open-sourcing for Python which lets you use SQL on pandas dataframes.\"",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "SQL for pandas DataFrames",
            "url": "http://blog.yhat.com/posts/pandasql-sql-for-pandas-dataframes.html"
        },
        {
            "author": "Zac Stewart",
            "description": "\"The following is a moderately detailed explanation and a few examples of how I use pipelining when I work on competitions.\"",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Using scikit-learn Pipelines and FeatureUnions",
            "url": "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
        },
        {
            "author": "Zac Stewart",
            "description": "\"To demonstrate text classification with scikit-learn, we're going to build a simple spam filter. While the filters in production for services like Gmail are vastly more sophisticated, the model we'll have by the end of this tutorial is effective, and surprisingly accurate.\"",
            "tags": [
                "Tutorials in Python",
                "Machine Learning Tutorials"
            ],
            "title": "Document Classification with scikit-learn",
            "url": "http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html"
        },
        {
            "author": "Ben Gorman",
            "description": "\"Stacking (also called meta ensembling) is a model ensembling technique used to combine information from multiple predictive models to generate a new model. Often times the stacked model (also called 2nd-level model) will outperform each of the individual models due its smoothing nature and ability to highlight each base model where it performs best and discredit each base model where it performs poorly. For this reason, stacking is most effective when the base models are significantly different. Here I provide a simple example and guide on how stacking is most often implemented in practice.\" Link to github repo with R code is provided.",
            "tags": [
                "R Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Guide to Model Stacking (i.e. Meta Ensembling)",
            "url": "https://gormanalysis.com/guide-to-model-stacking-i-e-meta-ensembling/"
        },
        {
            "author": "Kyle Polich",
            "description": "\"Data Skeptic is a podcast that alternates between short mini episodes and longer interviews. For the mini-episodes, Kyle and Linh Da explore basic data science concepts. Longer interviews feature practitioners and experts on interesting topics related to data, all through the eye of scientific skepticism.\"",
            "tags": [
                "Statistics Podcasts",
                "Beginner Statistics"
            ],
            "title": "Data Skeptic",
            "url": "http://dataskeptic.com/"
        },
        {
            "author": "John D. Cook",
            "description": "\"The following diagram summarizes conjugate prior relationships for a number of common sampling distributions.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Diagram of Bayesian Conjugate Priors",
            "url": "http://www.johndcook.com/blog/conjugate_prior_diagram/"
        },
        {
            "author": "Peter Norvig",
            "description": "\"When an experimental study states 'The group with treatment X had significantly less disease (p = 1%)', many people interpret this statement as being equivalent to 'there is a 99% chance that if I do treatment X it will prevent disease.' This essay explains why these statements are not equivalent.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Warning Signs in Experimental Design and Interpretation",
            "url": "http://norvig.com/experiment-design.html"
        },
        {
            "author": "Allen Downey",
            "description": "A distillation of hypothesis testing into a single framework.  A nice alternative to memorizing lots of classical tests.  Follow up posts <a href='http://allendowney.blogspot.com/2011/06/more-hypotheses-less-trivia.html'>here with lots of exmaples</a> and <a href='http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html'>here</a>",
            "tags": [
                "Statistics Misc"
            ],
            "title": "There is only one test!",
            "url": "http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html"
        },
        {
            "author": "Allen Downey",
            "description": "\"I present a probability puzzle, the Rain in Seattle Problem, and use it to explain differences between the Bayesian and frequentist interpretations of probability, and between Bayesian and frequentist statistical methods.  Since I am trying to clear up confusion, I try to describe the alternatives without commenting on their pros and cons.\"<br> It also features Allen Downey's Bayesian update worksheet, with the following steps:<br>1. Define hypotheses, making sure they are mututally exclusive and collectively exhaustive.<br>2. Choose priors, being careful not to let the data sneak in.<br>3.Compute the likelihood of the data under each hypothesis, thinking carefully about implicit modeling assumptions.<br>Note: No thinking required beyond this point.<br>4. Multiply priors and likelihoods to get unnormalized posteriors.<br>5.Add up the unnormalized posteriors to get the total probability of the data.<br>6. Divide the unnormalized posteriors by the total probability to get the posterior probabilities.",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Bayes's Theorem is not optional",
            "url": "http://allendowney.blogspot.com/2016/09/bayess-theorem-is-not-optional.html"
        },
        {
            "author": "Ben Klemens",
            "description": "\"This project lists open-form narratives and the closed-form distributions that approximate them. Its intent is to help you build estimable statistical models on a sound micro-level foundation.\"",
            "tags": [
                "Statistics Misc",
                "Beginner Statistics"
            ],
            "title": "A Table of Narratives and Generated Distributions",
            "url": "http://b-k.github.io/narratives-distributions/index.html"
        },
        {
            "author": "Kaggle",
            "description": "Interviews of Kaggle Compeition top finishers, and scripts shared by competitors.",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "No Free Hunch",
            "url": "http://blog.kaggle.com/"
        },
        {
            "author": "Sebatian Raschka",
            "description": "Blog of the author of the 'Python Machine Learning' book",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "Sebatian Raschka's Blog",
            "url": "http://sebastianraschka.com/blog/index.html"
        },
        {
            "author": "Sebatian Raschka",
            "description": "Part 1: <a href='http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html'>General ideas behind model evaluation in supervised machine learning</a><br>Part 2: <a href='http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html'>Some advanced techniques for model evaluation</a><br>Part 3: <a href='https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html'>Model evaluation, model selection, and algorithm selection in machine learning</a>",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Model evaluation, model selection, and algorithm selection in machine learning",
            "url": "http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html"
        },
        {
            "author": "Zygmunt Zaj\u0105c",
            "description": "\"This site is brought to you by the letters \u201cM\u201d and \u201cL\u201d. It is meant to tackle interesting topics in machine learning while being entertaining and easy to read and understand. FastML probably grew out of a frustration with papers you need a PhD in math to understand and with either no code or half-baked Matlab implementation of homework-assignment quality. We understand that some cutting-edge researchers might have no interest in providing the goodies for free, or just no interest in such down-to-earth matters. But we don't have time nor desire to become experts in every machine learning topic. Fortunately, there is quite a lot of good software with acceptable documentation.\"",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "Fast ML",
            "url": "http://fastml.com/"
        },
        {
            "author": "Chris Fonnesbeck",
            "description": "A worked exmaple of Hierarchical Modeling using pystan",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "A Primer on Bayesian Multilevel Modeling using PyStan",
            "url": "http://mc-stan.org/documentation/case-studies/radon.html"
        },
        {
            "author": "Aaron Kramer",
            "description": "\"This post is an introduction to Bayesian probability and inference. We will discuss the intuition behind these concepts, and provide some examples written in Python to help you get started. To get the most out of this introduction, the reader should have a basic understanding of statistics and probability, as well as some experience with Python. The examples use the Python package pymc3.\"",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Introduction to Bayesian Inference",
            "url": "https://www.datascience.com/blog/introduction-to-bayesian-inference-learn-data-science-tutorials"
        },
        {
            "author": "Yuan Tang",
            "description": "\"Scikit Flow is a simplified interface for TensorFlow, to get people started on predictive analytics and data mining. It helps smooth the transition from the Scikit-learn world of one-liner machine learning into the more open world of building different shapes of ML models. You can start by using fit/predict and slide into TensorFlow APIs as you are getting comfortable. It\u2019s Scikit-learn compatible so you can also benefit from Scikit-learn features like GridSearch and Pipeline.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Introduction to Scikit Flow",
            "url": "http://terrytangyuan.github.io/2016/03/14/scikit-flow-intro/"
        },
        {
            "author": "yhat",
            "description": "\"Ever heard people at your office talking about AUC, ROC, or TPR but been too shy to ask what the heck they're talking about? Well lucky for you we're going to be diving into the wonderful world of binary classification evaluation today. In particular, we'll be discussing ROC curves.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python",
                "R Tutorials"
            ],
            "title": "ROC Curves in Python and R",
            "url": "http://blog.yhat.com/posts/roc-curves.html"
        },
        {
            "author": "Kim Larsen",
            "description": "\"Despite its lack of popularity in the data science community, GAM is a powerful and yet simple technique. Hence, the purpose of this post is to convince more data scientists to use GAM. Of course, GAM is no silver bullet, but it is a technique you should add to your arsenal. Here are three key reasons: Easy to interpret; Flexible predictor functions can uncover hidden patterns in the data; Regularization of predictor functions helps avoid overfitting.\"",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "GAM: The Predictive Modeling Silver Bullet",
            "url": "http://multithreaded.stitchfix.com/blog/2015/07/30/gam/"
        },
        {
            "author": "Rasmus Baath",
            "description": "Series of posts on the Bayesian Bootstrap.<br><a href='http://sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/'>The non-parametric bootstrap as a Bayesian model</a><br><a href='http://www.sumsar.net/blog/2015/07/easy-bayesian-bootstrap-in-r/'>Easy Bayesian Bootstrap in R</a><br><a href='http://www.sumsar.net/blog/2016/02/bayesboot-an-r-package/'>bayesboot: An R packages</a><br><a href='https://www.youtube.com/watch?v=VceFc5hsMw8'>Presentation of bayesboot</a>",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "Bayesian Bootstrap",
            "url": "http://www.sumsar.net/blog/2016/02/bayesboot-an-r-package/"
        },
        {
            "author": "Ando Saabas",
            "description": "Example of using package treeinterpreter for insight into a scikit-learn RandomForest",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Random forest interpretation with scikit-learn",
            "url": "http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/"
        },
        {
            "author": "Kaggle user Triskelion",
            "description": "\"Model ensembling is a very powerful technique to increase accuracy on a variety of ML tasks. In this article I will share my ensembling approaches for Kaggle Competitions.\"",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Kaggle Ensembling Guide",
            "url": "http://mlwave.com/kaggle-ensembling-guide/"
        },
        {
            "author": "Fjodor Van Veen",
            "description": "\"With new neural network architectures popping up every now and then, it\u2019s hard to keep track of them all. Knowing all the abbreviations being thrown around (DCIGN, BiLSTM, DCGAN, anyone?) can be a bit overwhelming at first.<br>So I decided to compose a cheat sheet containing many of those architectures. Most of these are neural networks, some are completely different beasts. Though all of these architectures are presented as novel and unique, when I drew the node structures\u2026 their underlying relations started to make more sense.\"",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "The Neural Network Zoo",
            "url": "http://www.asimovinstitute.org/neural-network-zoo/"
        },
        {
            "author": "Andrej Karpathy",
            "description": "\"In other words, it is easy to fall into the trap of abstracting away the learning process\u200a\u2014\u200abelieving that you can simply stack arbitrary layers together and backprop will \u201cmagically make them work\u201d on your data. So lets look at a few explicit examples where this is not the case in quite unintuitive ways.\"",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Yes you should understand backprop",
            "url": "https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.deo6y636u"
        },
        {
            "author": "Ben Frederickson",
            "description": "\"Numerical Optimization is one of the central techniques in Machine Learning. For many problems it is hard to figure out the best solution directly, but it is relatively easy to set up a loss function that measures how good a solution is - and then minimize the parameters of that function to find the solution.\"",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "An Interactive Tutorial on Numerical Optimization",
            "url": "http://www.benfrederickson.com/numerical-optimization/"
        },
        {
            "author": "Scott Locklin",
            "description": "Explanation of conformal prediction for constructing confidence intervals for machine learning algorithms",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Predicting with confidence: the best machine learning idea you never heard of",
            "url": "https://scottlocklin.wordpress.com/2016/12/05/predicting-with-confidence-the-best-machine-learning-idea-you-never-heard-of/"
        },
        {
            "author": "Sebastian Raschka",
            "description": "A collection of tutorials and examples for solving and understanding machine learning and pattern classification tasks",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Pattern Classification",
            "url": "https://github.com/rasbt/pattern_classification"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"When we are applying machine learning algorithms to real-world applications, our computer hardware often still constitutes the major bottleneck of the learning process. Of course, we all have access to supercomputers, Amazon EC2, Apache Spark, etc. However, out-of-core learning via Stochastic Gradient Descent can still be attractive if we'd want to update our model on-the-fly ('online-learning'), and in this notebook, I want to provide some examples of how we can implement an 'out-of-core' approach using scikit-learn. I compiled the following code examples for personal reference, and I don't intend it to be a comprehensive reference for the underlying theory, but nonetheless, I decided to share it since it may be useful to one or the other!\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Out-of-core Learning and Model Persistence using scikit-learn",
            "url": "https://github.com/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
        },
        {
            "author": "Mark Needham",
            "description": "Tutorial on how to convert text data for training with a scikit-learn RandomForest Classifier",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Python: scikit-learn \u2013 Training a classifier with non numeric features",
            "url": "https://www.webcodegeeks.com/python/python-scikit-learn-training-classifier-non-numeric-features/"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"Here, I want to present a simple and conservative approach of implementing a weighted majority rule ensemble classifier in scikit-learn that yielded remarkably good results when I tried it in a kaggle competition.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Implementing a Weighted Majority Rule Ensemble Classifier",
            "url": "http://sebastianraschka.com/Articles/2014_ensemble_classifier.html"
        },
        {
            "author": "Nicolas Kruchten",
            "description": "\"A different way to look at graph analysis and visualization, as an introduction to a few cool algorithms: Truncated SVD, K-Means and t-SNE with a practical walkthrough using scikit-learn and friends numpy and bokeh, and finishing off with some more general commentary on this approach to data analysis.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Data Science and (Unsupervised) Machine Learning with scikit-learn",
            "url": "http://opensource.datacratic.com/mtlpy50/"
        },
        {
            "author": "Martin Wattenberg, Fernanda Vi\u00e9gas, Ian Johnson",
            "description": "\"Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading. By exploring how it behaves in simple cases, we can learn to use it more effectively.\"",
            "tags": [
                "Machine Learning Misc",
                "Visualization Misc"
            ],
            "title": "How to Use t-SNE Effectively",
            "url": "http://distill.pub/2016/misread-tsne/"
        },
        {
            "author": "Zygmunt Zaj\u0105c",
            "description": "\"Calibration is applicable in case a classifier outputs probabilities. Apparently some classifiers have their typical quirks - for example, they say boosted trees and SVM tend to predict probabilities conservatively, meaning closer to mid-range than to extremes. If your metric cares about exact probabilities, like logarithmic loss does, you can calibrate the classifier, that is post-process the predictions to get better estimates.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Classifier calibration with Platt's scaling and isotonic regression",
            "url": "http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/"
        },
        {
            "author": "Edwin Chen",
            "description": "\"A couple weeks ago, Facebook launched a link prediction contest on Kaggle, with the goal of recommending missing edges in a social graph. I love investigating social networks, so I dug around a little, and since I did well enough to score one of the coveted prizes, I\u2019ll share my approach here.\"",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Edge Prediction in a Social Graph: My Solution to Facebook's User Recommendation Contest on Kaggle",
            "url": "http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/"
        },
        {
            "author": "Austin Rochford",
            "description": "\"In this post, we\u2019ll explore a Bayesian approach to nonparametric regression, which allows us to model complex functions with relatively weak assumptions.\" Extends scikit-learn.",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "Nonparametric Bayesian Regression with Gaussian Processes",
            "url": "http://austinrochford.com/posts/2014-03-23-bayesian-nonparamtric-regression-gp.html"
        },
        {
            "author": "Max Kuhn",
            "description": "\"I'll demonstrate how Bayesian optimization and Gaussian process models can be used as an alternative.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Bayesian Optimization of Machine Learning Models",
            "url": "http://blog.revolutionanalytics.com/2016/06/bayesian-optimization-of-machine-learning-models.html"
        },
        {
            "author": "John Mount",
            "description": "\"This article is a demonstration the use of the R vtreat variable preparation package followed by caret controlled training.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "A demonstration of vtreat data preparation",
            "url": "http://www.win-vector.com/blog/2016/06/a-demonstration-of-vtreat-data-preparation/"
        },
        {
            "author": "Nina Zumel",
            "description": "Part I: <a href='http://www.win-vector.com/blog/2016/05/pcr_part1_xonly'>The Standard Method</a><br>Part II: <a href='http://www.win-vector.com/blog/2016/05/pcr_part2_yaware/'>Y-Aware Methods</a><br>Part III: <a href='http://www.win-vector.com/blog/2016/05/pcr_part3_pickk/'>Picking the Number of Components</a>",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "Principal Components Regression",
            "url": "http://www.win-vector.com/blog/2016/05/pcr_part1_xonly/"
        },
        {
            "author": "John Mount",
            "description": "Part 1: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart1/'>Setting up the specific problem for modeling.</a><br>Part 2: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart2/'>In-training set measures</a><br>Part 3: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart3/'>Out of sample procedures</a><br>Part 4: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart4/'>Cross-validation techniques</a>",
            "tags": [
                "Statistics Misc"
            ],
            "title": "How do you know if your model is going to work?",
            "url": "http://www.win-vector.com/blog/2015/09/willyourmodelworkpart1/"
        },
        {
            "author": "John Mount",
            "description": "Sample size calculation and visualization for power and significance specifications.",
            "tags": [
                "Statistics Misc",
                "R Tutorials"
            ],
            "title": "A clear picture of power and significance in A/B tests",
            "url": "http://www.win-vector.com/blog/2014/05/a-clear-picture-of-power-and-significance-in-ab-tests/"
        },
        {
            "author": "John Mount",
            "description": "\"In this article we are going to work a simple (but important) problem where (for once) the Bayesian calculations are in fact easier than the frequentist ones.\"",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Frequentist inference only seems easy",
            "url": "http://www.win-vector.com/blog/2014/07/frequenstist-inference-only-seems-easy/"
        },
        {
            "author": "Nina Zumel",
            "description": "Tutorial for graphing with ggplot2 in R",
            "tags": [
                "Visualization Tutorials",
                "R Tutorials"
            ],
            "title": "The Extra Step: Graphs for Communication versus Exploration",
            "url": "http://www.win-vector.com/blog/2014/01/the-extra-step-graphs-for-communication-versus-exploration/"
        },
        {
            "author": "Joseph Rickert",
            "description": "\"Performing feature selection with GAs requires conceptualizing the process of feature selection as an optimization problem and then mapping it to the genetic framework of random variation and natural selection.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Feature Selection with caret's Genetic Algorithm Option",
            "url": "http://blog.revolutionanalytics.com/2015/12/caret-genetic.html"
        },
        {
            "author": "Joseph Rickert",
            "description": "\"Here, I fit a randomForest model to eight features from the UCI MPG data set and use the randomForestInfJack() function to calculate the infinitesimal Jackknife estimator.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Confidence Intervals for Random Forests",
            "url": "http://blog.revolutionanalytics.com/2016/03/confidence-intervals-for-random-forest.html"
        },
        {
            "author": "Sharon Machlis",
            "description": "\"Our aim here isn't R mastery, but giving you a path to start using R for basic data work: Extracting key statistics out of a data set, exploring a data set with basic graphics and reshaping data to make it easier to analyze.\"",
            "tags": [
                "Beginner R",
                "R Tutorials"
            ],
            "title": "Beginner's guide to R: Introduction",
            "url": "http://www.computerworld.com/article/2497143/business-intelligence/business-intelligence-beginner-s-guide-to-r-introduction.html"
        },
        {
            "author": "Sharon Machlis",
            "description": "\"Learn how to wrangle data, including using R's transform, apply and mapply functions, along with sorting, grouping by date range and reshaping. We also take you through some dplyr basics.\"",
            "tags": [
                "Beginner R",
                "R Tutorials"
            ],
            "title": "Advanced Beginner's Guide to R",
            "url": "http://www.computerworld.com/resources/106345/advanced-beginners-guide-to-r.html"
        },
        {
            "author": "Max Woolf",
            "description": "Tutorial for making nicely styled charts with R and ggplot2.",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "An Introduction on How to Make Beautiful Charts With R and ggplot2",
            "url": "http://minimaxir.com/2015/02/ggplot-tutorial/"
        },
        {
            "author": "Megan Risdal",
            "description": "\"In this blog post, I feature some great user kernels as mini-tutorials for getting started with mapping using datasets published on Kaggle. You\u2019ll learn about several ways to wrangle and visualize geospatial data in Python and R including real code examples. I've also included resources so you can learn more about each of the packages highlighted in each tutorial as well as further user analyses for more inspiration.\"",
            "tags": [
                "Tutorials in Python",
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "Seventeen Ways to Map Data in Kaggle Kernels: Tutorials for Python and R Users",
            "url": "http://blog.kaggle.com/2016/11/30/seventeen-ways-to-map-data-in-kaggle-kernels/"
        },
        {
            "author": "Max Woolf",
            "description": "\"Here are some tips and tutorials on how to make such visualizations.\"",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "How to Visualize New York City Using Taxi Location Data and ggplot2",
            "url": "http://minimaxir.com/2015/11/nyc-ggplot2-howto/"
        },
        {
            "author": "Krzysztof Osiewalski",
            "description": "\"In this article we give some hints on how to use your machine in most efficient way while programming in R and when this can be achieved.\"",
            "tags": [
                "R Tutorials"
            ],
            "title": "Unleash the power of your multi-core CPU with R",
            "url": "http://www.marketingdistillery.com/2014/11/29/unleash-the-power-of-your-multi-core-cpu-with-r/"
        },
        {
            "author": "Kim Larsen",
            "description": "Tutorial on using Bayesian structural time series models.",
            "tags": [
                "R Tutorials",
                "Statistics Tutorials"
            ],
            "title": "Sorry ARIMA, but I\u2019m Going Bayesian",
            "url": "http://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/"
        },
        {
            "author": "Max Kuhn",
            "description": "\"Max Kuhn, author of Applied Predictive Modeling and caret package, will talk about the practice of predictive modeling. The practice of predictive modeling defines the process of developing a model in a way that we can understand and quantify the model's prediction accuracy on future data.\"",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "R: Applied Predictive Modeling",
            "url": "https://www.youtube.com/watch?v=99lnTku75Pc"
        },
        {
            "author": "Jake Vanderplas",
            "description": "Part I: <a href='http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/'>A Practical Introduction</a><br>Part II: <a href='http://jakevdp.github.io/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/'>When Results Differ</a><br>Part III: <a href='http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/'>Confidence, Credibility, and why Frequentism and Science do not Mix</a><br>Part IV: <a href='http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/'>How to be a Bayesian in Python</a><br>Part V: <a href='https://jakevdp.github.io/blog/2015/08/07/frequentism-and-bayesianism-5-model-selection/'>Model Selection</a>",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Frequentism and Bayesianism",
            "url": "http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/"
        },
        {
            "author": "Jake Vanderplas",
            "description": "\"Statistics has the reputation of being difficult to understand, but using some simple Python skills it can be made much more intuitive. This talk will cover several sampling-based approaches to solving statistical problems, and show you that if you can write a for-loop, you can do statistics.\"",
            "tags": [
                "Statistics Lectures",
                "Beginner Statistics"
            ],
            "title": "Statistics for Hackers - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=L5GVOFAYi8k"
        },
        {
            "author": "Jake Vanderplas",
            "description": "\"Statistics has the reputation of being difficult to understand, but using some simple Python skills it can be made much more intuitive. This talk will cover several sampling-based approaches to solving statistical problems, and show you that if you can write a for-loop, you can do statistics.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Tutorials in Python"
            ],
            "title": "PyCon 2015 Introduction to Scikit-Learn tutorial",
            "url": "http://nbviewer.jupyter.org/github/jakevdp/sklearn_pycon2015/blob/master/notebooks/Index.ipynb"
        },
        {
            "author": "OverAPI.com",
            "description": "Quick reference for regular expressions",
            "tags": [
                "Programming Misc"
            ],
            "title": "RegEx Cheat Sheet",
            "url": "http://overapi.com/regex"
        },
        {
            "author": "Lei Gong",
            "description": "\"However, deploying predictive model to a production environment, or serving the model in production, is a bit more complicated. Its architecture largely depends on how the model will be used. At very high level, predictive models often are used to score some instances, e.g. the risk score of fraud transaction or the likelihood of clicking on ads. This scoring operation can be offline or online, depending on its application. Offline scoring means the model doesn\u2019t needs to score an instance in real-time and online scoring means the model is required to score with real-time input and low-latency. In this post, I am going to touch on a few common architectures and their use cases.<p>Follow up post <a href='http://commitlogs.com/2016/12/17/predictive-model-deployment-missing-components/'>about continuous deployment aspects here</a>.\"",
            "tags": [
                "Programming Misc",
                "Machine Learning Misc"
            ],
            "title": "Predictive Model Deployment with Spark",
            "url": "http://commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/"
        },
        {
            "author": "Jean Francois Puget",
            "description": "Description of how to use the Python subprocess package to use command line applications within a Python environment.",
            "tags": [
                "Tutorials in Python"
            ],
            "title": "Using Python Subprocess To Drive Machine Learning Packages",
            "url": "https://www.ibm.com/developerworks/community/blogs/jfp/entry/Using_Python_Subprocess_To_Drive_Machine_Learning_Packages?lang=en"
        },
        {
            "author": "Tom Augspurger",
            "description": "Series of posts covering Indexing, Method Chaining, Indexes, Fast Pandas, Tidy Data, Visualization, and Time Series",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Modern Pandas",
            "url": "https://tomaugspurger.github.io/modern-1.html"
        },
        {
            "author": "Julia Evans",
            "description": "\"The goal of this cookbook is to give you some concrete examples for getting started with pandas. The docs are really comprehensive. However, I've often had people tell me that they have some trouble getting started, so these are examples with real-world data, and all the bugs and weirdness that entails.\"",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Pandas cookbook",
            "url": "https://github.com/jvns/pandas-cookbook"
        },
        {
            "author": "Data Camp",
            "description": "One page reference for pandas",
            "tags": [
                "Python Misc"
            ],
            "title": "Python For Data Science Cheat Sheet",
            "url": "https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf"
        },
        {
            "author": "Jay Feng",
            "description": "Demonstration of how to apply a function to pandas in parallel.",
            "tags": [
                "Python Pandas Tutorials"
            ],
            "title": "Python Pandas Functions in Parallel",
            "url": "http://www.racketracer.com/2016/07/06/pandas-in-parallel/"
        },
        {
            "author": "Curtis Miller",
            "description": "\"In these posts, I will discuss basics such as obtaining the data from Yahoo! Finance using pandas, visualizing stock data, moving averages, developing a moving-average crossover strategy, backtesting, and benchmarking. The final post will include practice problems. This first post discusses topics up to introducing moving averages.\" Part 2 is <a href='https://ntguardian.wordpress.com/2016/09/26/introduction-stock-market-data-python-2/'>here</a>.",
            "tags": [
                "Tutorials in Python",
                "Finance"
            ],
            "title": "An Introduction to Stock Market Data Analysis with Python ",
            "url": "https://ntguardian.wordpress.com/2016/09/19/introduction-stock-market-data-python-1/"
        },
        {
            "author": "Chris Mofitt",
            "description": "Builds an amortization schedule in Pandas.",
            "tags": [
                "Tutorials in Python",
                "Finance"
            ],
            "title": "Building a Financial Model with Pandas - Version 2",
            "url": "http://pbpython.com/amortization-model-revised.html"
        },
        {
            "author": "Evan Miller",
            "description": "\"Intuitive statistical calculators, ideal for planning and analyzing A/B tests.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Evan's Awesome A/B Tools",
            "url": "http://www.evanmiller.org/ab-testing/"
        },
        {
            "author": "Online Dialogue",
            "description": "\"Play with the controls and get a better feel for how a lower confidence level will boost the power or how an increase in test size can make a small CR-difference significant.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "AB Testing Guide",
            "url": "http://abtestguide.com/calc/"
        },
        {
            "author": "Andrew Gelman",
            "description": "Demonstration of how informative priors can escape the multiple comparison problem.",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Bayesian inference completely solves the multiple comparisons problem",
            "url": "http://andrewgelman.com/2016/08/22/bayesian-inference-completely-solves-the-multiple-comparisons-problem/"
        },
        {
            "author": "Andrew Gelman1 and John Carlin",
            "description": "\"Statistical power analysis provides the conventional approach to assess error rates when designing a research study. However, power analysis is flawed in that a narrow emphasis on statistical significance is placed as the primary focus of study design. In noisy, small-sample settings, statistically significant results can often be misleading. To help researchers address this problem in the context of their own studies, we recommend design calculations in which (a) the probability of an estimate being in the wrong direction (Type S [sign] error) and (b) the factor by which the magnitude of an effect might be overestimated (Type M [magnitude] error or exaggeration ratio) are estimated. We illustrate with examples from recent published research and discuss the largest challenge in a design calculation: coming up with reasonable estimates of plausible effect sizes based on external information.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors",
            "url": "http://www.stat.columbia.edu/~gelman/research/published/retropower_final.pdf"
        },
        {
            "author": "Adam Kelleher",
            "description": "Series of posts addressing casuality",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Causal Data Science",
            "url": "https://medium.com/@akelleh/causal-data-science-721ed63a4027#.lzne8nsk2"
        },
        {
            "author": "Patrick Riley",
            "description": "\"I put together a document shared Google-wide which I optimistically and simply titled 'Good Data Analysis.'  The advice is organized into three general areas:<br>Technical: Ideas and techniques for how to manipulate and examine your data.<br>Process: Recommendations on how you approach your data, what questions to ask, and what things to check.<br>Social: How to work with others and communicate about your data and insights.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Practical advice for analysis of large, complex data sets",
            "url": "http://www.unofficialgoogledatascience.com/2016/10/practical-advice-for-analysis-of-large.html"
        },
        {
            "author": "Manojit Nandi",
            "description": "\"In this post, I discuss a method for A/B testing using Beta-Binomial Hierarchical models to correct for a common pitfall when testing multiple hypotheses. I will compare it to the classical method of using Bernoulli models for p-value, and cover other advantages hierarchical models have over the classical model.\" Uses pymc in Python 2.",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "A/B Testing with Hierarchical Models in Python",
            "url": "https://blog.dominodatalab.com/ab-testing-with-hierarchical-models-in-python/"
        },
        {
            "author": "Dan Saber",
            "description": "Example of A/B testing with hierarchical models using pymc3.",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Analyze Your Experiment with a Multilevel Logistic Regression using PyMC3",
            "url": "https://dansaber.wordpress.com/2016/08/27/analyze-your-experiment-with-a-multilevel-logistic-regression-using-pymc3%E2%80%8B/"
        },
        {
            "author": "Bob Carpenter, Jonah Gabry and Ben Goodrich",
            "description": "\"This vignette illustrates the effects on posterior inference of pooling data (a.k.a sharing strength) across units for repeated binary trial data. It provides R code to fit and check predictive models for three situations: (a) complete pooling, which assumes each unit is the same, (b) no pooling, which assumes the units are unrelated, and (c) partial pooling, where the similarity among the units is estimated. The note explains with working examples how to (i) fit the models using rstanarm and plot the results, (ii) estimate event probabilities, (iii) evaluate posterior predictive densities to evaluate model predictions on held-out data, (iv) rank units by chance of success, (v) perform multiple comparisons in several settings, (vi) replicate new data for posterior pp-values, and (vii) perform graphical posterior predictive checks.\"",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "Hierarchical Partial Pooling for Repeated Binary Trials",
            "url": "https://cran.r-project.org/web/packages/rstanarm/vignettes/pooling.html"
        },
        {
            "author": "Slater Stich",
            "description": "Demonstration of Hierarchical Models in A/B tests using pymc.",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "A/B Testing Statistics",
            "url": "http://sl8r000.github.io/ab_testing_statistics/use_a_hierarchical_model/"
        },
        {
            "author": "Tuomas Sivula",
            "description": "\"This repository contains some Python demos for the book Bayesian Data Analysis, 3rd ed by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (BDA3).\"",
            "tags": [
                "Statistics Tutorials",
                "Tutorials in Python"
            ],
            "title": "Bayesian Data Analysis Python Demos",
            "url": "https://github.com/avehtari/BDA_py_demos"
        },
        {
            "author": "Markus Paasiniemi",
            "description": "\"This repository contains some R demos for the book Bayesian Data Analysis, 3rd ed by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (BDA3).\"",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "Bayesian Data Analysis R Demos",
            "url": "https://github.com/avehtari/BDA_R_demos"
        },
        {
            "author": "Richard L. Halterman",
            "description": "Thorough book covering many aspects of software development in Python.  Uses Python 3.",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Fundamentals of Python Programming",
            "url": "http://python.cs.southern.edu/pythonbook/pythonbook.pdf"
        },
        {
            "author": "Andrew Gelman",
            "description": "A list of regression assumptions, in decreasing order of importance.",
            "tags": [
                "Statistics Misc"
            ],
            "title": "What are the key assumptions of linear regression?",
            "url": "http://andrewgelman.com/2013/08/04/19470/"
        },
        {
            "author": "UCLA",
            "description": "Resources to help you learn and use R",
            "tags": [
                "R Tutorials"
            ],
            "title": "Resources to help you learn and use R",
            "url": "http://www.ats.ucla.edu/stat/r/"
        },
        {
            "author": "Adam Harasimowicz",
            "description": "\"Parallel computing is easy to use in R thanks to packages like doParallel. However, before we decide to parallelize our code, still we should remember that there is a trade-off between simplicity and performance. So if your script runs a few seconds, probably it's not worth to bother yourself. Yet if your analysis are computationally heavy, you can often save hours or even days. In such case, it's reasonable to sacrifice code readability and clear error messages to save time.\"",
            "tags": [
                "R Tutorials"
            ],
            "title": "R: Parallel Computing In 5 Minutes (with foreach and doParallel)",
            "url": "http://blog.aicry.com/r-parallel-computing-in-5-minutes/"
        }
    ]
}
