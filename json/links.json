{
    "links": [
        {
            "author": "Allen Downey",
            "description": "\"Think Python is an introduction to Python programming for beginners. It starts with basic concepts of programming, and is carefully designed to define all terms when they are first used and to develop each new concept in a logical progression. Larger pieces, like recursion and object-oriented programming are divided into a sequence of smaller steps and introduced over the course of several chapters.\" Uses Python 3.",
            "tags": [
                "Python Textbooks",
                "Beginner Python"
            ],
            "title": "Think Python 2e",
            "url": "http://greenteapress.com/wp/think-python-2e/"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Python is an introduction to Python programming for beginners. It starts with basic concepts of programming, and is carefully designed to define all terms when they are first used and to develop each new concept in a logical progression. Larger pieces, like recursion and object-oriented programming are divided into a sequence of smaller steps and introduced over the course of several chapters.\" Uses Python 2.",
            "tags": [
                "Python Textbooks",
                "Beginner Python"
            ],
            "title": "Think Python 1e",
            "url": "http://greenteapress.com/wp/think-python/"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Stats is an introduction to Probability and Statistics for Python programmers. Think Stats emphasizes simple techniques you can use to explore real data sets and answer interesting questions. The book presents a case study using data from the National Institutes of Health. Readers are encouraged to work on a project with real datasets. If you have basic skills in Python, you can use them to learn concepts in probability and statistics. Think Stats is based on a Python library for probability distributions (PMFs and CDFs). Many of the exercises use short programs to run experiments and help readers develop understanding.\"",
            "tags": [
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Think Stats 2e",
            "url": "http://greenteapress.com/thinkstats2/index.html"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think Bayes is an introduction to Bayesian statistics using computational methods. Most books on Bayesian statistics use mathematical notation and present ideas in terms of mathematical concepts like calculus. This book uses Python code instead of math, and discrete approximations instead of continuous mathematics. As a result, what would be an integral in a math book becomes a summation, and most operations on probability distributions are simple loops.\"",
            "tags": [
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Think Bayes",
            "url": "http://greenteapress.com/wp/think-bayes/"
        },
        {
            "author": "Allen Downey",
            "description": "\"This book is about complexity science, data structures and algorithms, intermediate programming in Python, and the philosophy of science.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Think Complexity",
            "url": "http://greenteapress.com/complexity/index.html"
        },
        {
            "author": "Allen Downey",
            "description": "\"Think DSP is an introduction to Digital Signal Processing in Python.\"",
            "tags": [
                "Statistics Textbooks"
            ],
            "title": "Think DSP",
            "url": "http://greenteapress.com/wp/think-dsp/"
        },
        {
            "author": "Gary W. Oehlert",
            "description": "\"This text covers the basic topics in experimental design and analysis and is intended for graduate students and advanced undergraduates. Students should have had an introductory statistical methods course at about the level of Moore and McCabe's Introduction to the Practice of Statistics (Moore and McCabe 1999) and be familiar with t-tests, p-values, confidence intervals, and the basics of regression and ANOVA.\"",
            "tags": [
                "Statistics Textbooks"
            ],
            "title": "A First Course in Design and Analysis of Experiments",
            "url": "http://users.stat.umn.edu/~gary/book/fcdae.pdf"
        },
        {
            "author": "David J.C. MacKay",
            "description": "\"This book is aimed at senior undergraduates and graduate students in Engineering, Science, Mathematics, and Computing. It expects familiarity with calculus, probability theory, and linear algebra as taught in a first- or secondyear undergraduate course on mathematics for scientists and engineers. Conventional courses on information theory cover not only the beautiful theoretical ideas of Shannon, but also practical solutions to communication problems. This book goes further, bringing in Bayesian data modelling, Monte Carlo methods, variational methods, clustering algorithms, and neural networks.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks"
            ],
            "title": "Information Theory, Inference, and Learning Algorithms",
            "url": "http://www.inference.phy.cam.ac.uk/itila/"
        },
        {
            "author": "Jure Leskovec, Anand Rajaraman, Jeff Ullman (Stanford University)",
            "description": "\"The book is based on Stanford Computer Science course CS246: Mining Massive Datasets (and CS345A: Data Mining). The book, like the course, is designed at the undergraduate computer science level with no formal prerequisites. To support deeper explorations, most of the chapters are supplemented with further reading references.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Mining Massive Datasets",
            "url": "http://www.mmds.org/#ver21"
        },
        {
            "author": "Carl Edward Rasmussen and Christopher K. I. Williams",
            "description": "\"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "url": "http://www.gaussianprocess.org/gpml/"
        },
        {
            "author": "Max Welling",
            "description": "A nice introduction to various algorithms, with intuitive explanations of the formulas.",
            "tags": [
                "Machine Learning Textbooks",
                "Beginner Machine Learning"
            ],
            "title": "A First Encounter with Machine Learning",
            "url": "https://www.ics.uci.edu/~welling/teaching/ICS273Afall11/IntroMLBook.pdf"
        },
        {
            "author": "David Barber",
            "description": "\"The book is designed to appeal to students with only a modest mathematical background in undergraduate calculus and linear algebra. No formal computer science or statistical background is required to follow the book, although a basic familiarity with probability, calculus and linear algebra would be useful. The book should appeal to students from a variety of backgrounds, including Computer Science, Engineering, applied Statistics, Physics, and Bioinformatics that wish to gain an entry to probabilistic approaches in Machine Learning. In order to engage with students, the book introduces fundamental concepts in inference using only minimal reference to algebra and calculus. More mathematical techniques are postponed until as and when required, always with the concept as primary and the mathematics secondary.\"",
            "tags": [
                "Machine Learning Textbooks",
                "Statistics Textbooks"
            ],
            "title": "Bayesian Reasoning and Machine Learning",
            "url": "http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online"
        },
        {
            "author": "Richard S. Sutton and Andrew G. Barto",
            "description": "\"The book consists of three parts. Part I is introductory and problem oriented. We focus on the simplest aspects of reinforcement learning and on its main distinguishing features. One full chapter is devoted to introducing the reinforcement learning problem whose solution we explore in the rest of the book. Part II presents what we see as the three most important elementary solution methods: dynamic programming, simple Monte Carlo methods, and temporal-difference learning. The first of these is a planning method and assumes explicit knowledge of all aspects of a problem, whereas the other two are learning methods. Part III is concerned with generalizing these methods and blending them. Eligibility traces allow unification of Monte Carlo and temporal-difference methods, and function approximation methods such as artificial neural networks extend all the methods so that they can be applied to much larger problems. We bring planning and learning methods together again and relate them to heuristic search. Finally, we summarize our view of the state of reinforcement learning research and briefly present case studies, including some of the most impressive applications of reinforcement learning to date.\"",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Reinforcement Learning: An Introduction ",
            "url": "http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html"
        },
        {
            "author": "Cosma Rohilla Shalizi",
            "description": "\"This book began as the notes for 36-402, Advanced Data Analysis, at Carnegie Mellon University... ADA is a class in statistical methodology: its aim is to get students to understand something of the range of modern methods of data analysis, and of the considerations which go into choosing the right method for the job at hand (rather than distorting the problem to fit the methods you happen to know). Statistical theory is kept to a minimum, and largely introduced as needed. Since ADA is also a class in data analysis, there are a lot of assignments in which large, real data sets are analyzed with the new methods.\"",
            "tags": [
                "Statistics Textbooks",
                "R Textbooks"
            ],
            "title": "Advanced Data Analysis from an Elementary Point of View",
            "url": "http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/"
        },
        {
            "author": "Muhammad Yasoob Ullah Khalid",
            "description": "\"The topics which are discussed in this book open up your mind towards some nice corners of Python language. This book is an outcome of my desire to have something like this when I was beginning to learn Python.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Intermediate Python",
            "url": "http://book.pythontips.com/en/latest/"
        },
        {
            "author": "Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani",
            "description": "\"This book provides an introduction to statistical learning methods. It is aimed for upper level undergraduate students, masters students and Ph.D. students in the non-mathematical sciences. The book also contains a number of R labs with detailed explanations on how to implement the various methods in real life settings, and should be a valuable resource for a practicing data scientist.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks",
                "R Textbooks",
                "Beginner Machine Learning"
            ],
            "title": "An Introduction to Statistical Learning",
            "url": "http://www-bcf.usc.edu/~gareth/ISL/"
        },
        {
            "author": "Trevor Hastie, Robert Tibshirani, Jerome Friedman",
            "description": "\"During the past decade has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book descibes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book.\"",
            "tags": [
                "Statistics Textbooks",
                "Machine Learning Textbooks",
                "R Textbooks"
            ],
            "title": "The Elements of Statistical Learning",
            "url": "http://statweb.stanford.edu/~tibs/ElemStatLearn/"
        },
        {
            "author": "Zico Kolter (updated by Chuong Do)",
            "description": "A concise overview of linear algebra.",
            "tags": [
                "Math Textbooks"
            ],
            "title": "Linear Algebra Review and Reference",
            "url": "https://www.cs.cmu.edu/~15381/slides/linalg_notes.pdf"
        },
        {
            "author": "Roger Levy",
            "description": "\"I'm in the process of writing a textbook on the topic of using probabilistic models in scientific work on language ranging from experimental data analysis to corpus work to cognitive modeling. The intended audience is graduate students in linguistics, psychology, cognitive science, and computer science who are interested in using probabilistic models to study language.\"",
            "tags": [
                "R Textbooks",
                "Statistics Textbooks"
            ],
            "title": "Probabilistic Models in the Study of Language",
            "url": "http://idiom.ucsd.edu/~rlevy/pmsl_textbook/text.html"
        },
        {
            "author": "Ani Adhikari and John DeNero",
            "description": "\"Data are descriptions of the world around us, collected through observation and stored on computers. Computers enable us to infer properties of the world from these descriptions. Data science is the discipline of drawing conclusions from data using computation. There are three core aspects of effective data analysis: exploration, prediction, and inference. This text develops a consistent approach to all three, introducing statistical ideas and fundamental ideas in computer science concurrently. We focus on a minimal set of core techniques that they apply to a vast range of real-world applications. A foundation in data science requires not only understanding statistical and computational techniques, but also recognizing how they apply to real scenarios.\" Uses Python 3.",
            "tags": [
                "Python Textbooks",
                "Statistics Textbooks",
                "Beginner Statistics"
            ],
            "title": "Computational and Inferential Thinking",
            "url": "http://www.inferentialthinking.com/"
        },
        {
            "author": "Cam Davidson-Pilon",
            "description": "\"Bayesian Methods for Hackers is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical-background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.\"",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "Probabilistic Programming and Bayesian Methods for Hackers",
            "url": "https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers"
        },
        {
            "author": "Robert Ghrist and David Lonoff",
            "description": "Wiki of Calculus topics",
            "tags": [
                "Math Textbooks"
            ],
            "title": "The PennCalcWiki",
            "url": "http://calculus.seas.upenn.edu/"
        },
        {
            "description": "\"Simple and efficient tools for data mining and data analysis.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "scikit-learn",
            "url": "http://scikit-learn.org/stable/"
        },
        {
            "description": "Flow chart for Machine Learning Algorithms in scikit-learn.",
            "tags": [
                "Machine Learning Misc",
                "Beginner Machine Learning"
            ],
            "title": "scikit-learn algorithm cheat sheet",
            "url": "http://scikit-learn.org/stable/tutorial/machine_learning_map/"
        },
        {
            "description": "\"*pandas* is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\"",
            "tags": [
                "Python Packages"
            ],
            "title": "pandas",
            "url": "http://scikit-learn.org/stable/"
        },
        {
            "description": "\"Statsmodels is a Python module that allows users to explore data, estimate statistical models, and perform statistical tests. An extensive list of descriptive statistics, statistical tests, plotting functions, and result statistics are available for different types of data and each estimator.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "Statsmodels",
            "url": "http://statsmodels.sourceforge.net/"
        },
        {
            "description": "\"NumPy is the fundamental package for scientific computing with Python. It contains among other things:  a powerful N-dimensional array object; sophisticated (broadcasting) functions; tools for integrating C/C++ and Fortran code; useful linear algebra, Fourier transform, and random number capabilities.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "NumPy",
            "url": "http://www.numpy.org/"
        },
        {
            "description": "\"It provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "SciPy",
            "url": "https://www.scipy.org/scipylib/index.html"
        },
        {
            "description": "\"matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell..., web application servers, and six graphical user interface toolkits.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "matplotlib",
            "url": "http://matplotlib.org/"
        },
        {
            "description": "\"SymPy is a Python library for symbolic mathematics. It aims to become a full-featured computer algebra system (CAS) while keeping the code as simple as possible in order to be comprehensible and easily extensible. SymPy is written entirely in Python.\"",
            "tags": [
                "Python Packages",
                "Math Packages"
            ],
            "title": "SymPy",
            "url": "http://www.sympy.org/en/index.html"
        },
        {
            "description": "\"Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "Seaborn",
            "url": "https://web.stanford.edu/~mwaskom/software/seaborn/"
        },
        {
            "description": "\"Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. Its goal is to provide elegant, concise construction of novel graphics in the style of D3.js, and to extend this capability with high-performance interactivity over very large or streaming datasets. Bokeh can help anyone who would like to quickly and easily create interactive plots, dashboards, and data applications.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "Bokeh",
            "url": "http://bokeh.pydata.org/en/latest/"
        },
        {
            "description": "\"ggplot is a plotting system for Python based on R's ggplot2 and the Grammar of Graphics. It is built for making profressional looking, plots quickly with minimal code.\"",
            "tags": [
                "Python Packages",
                "Visualization Packages"
            ],
            "title": "ggplot",
            "url": "http://ggplot.yhathq.com/"
        },
        {
            "description": "\"TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization. The system is designed to facilitate research in machine learning, and to make it quick and easy to transition from research prototype to production system.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "TensorFlow",
            "url": "https://www.tensorflow.org/"
        },
        {
            "description": "\"PyMC3 is a python module for Bayesian statistical modeling and model fitting which focuses on advanced Markov chain Monte Carlo fitting algorithms. Its flexibility and extensibility make it applicable to a large suite of problems.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "PyMC3",
            "url": "http://pymc-devs.github.io/pymc3/"
        },
        {
            "description": "\"PyStan provides an interface to Stan, a package for Bayesian inference using the No-U-Turn sampler, a variant of Hamiltonian Monte Carlo.\"",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "PyStan",
            "url": "https://pystan.readthedocs.io/en/latest/"
        },
        {
            "description": "\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "NLTK",
            "url": "http://www.nltk.org/"
        },
        {
            "description": "\"spaCy helps you write programs that do clever things with text. You give it a string of characters, it gives you an object that provides multiple useful views of its meaning and linguistic structure. Specifically, spaCy features a high performance tokenizer, part-of-speech tagger, named entity recognizer and syntactic dependency parser, with built-in support for word vectors. All of the functionality is united behind a clean high-level Python API, that makes it easy to use the different annotations together.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "spaCy",
            "url": "https://spacy.io/"
        },
        {
            "description": "\"Fuzzy string matching like a boss. It uses Levenshtein Distance to calculate the differences between sequences in a simple-to-use package.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "FuzzyWuzzy",
            "url": "https://github.com/seatgeek/fuzzywuzzy"
        },
        {
            "description": "\"OpenCV is released under a BSD license and hence it\u2019s free for both academic and commercial use. It has C++, C, Python and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV was designed for computational efficiency and with a strong focus on real-time applications.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "OpenCV-Python",
            "url": "http://opencv.org/"
        },
        {
            "description": "\"SimpleCV is an open source framework for building computer vision applications. With it, you get access to several high-powered computer vision libraries such as OpenCV \u2013 without having to first learn about bit depths, file formats, color spaces, buffer management, eigenvalues, or matrix versus bitmap storage. This is computer vision made easy.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "Simple CV",
            "url": "http://simplecv.org/"
        },
        {
            "description": "\"scikit-image is a collection of algorithms for image processing. It is available free of charge and free of restriction. We pride ourselves on high-quality, peer-reviewed code, written by an active community of volunteers.\"",
            "tags": [
                "Machine Learning Packages",
                "Python Packages"
            ],
            "title": "scikit-image",
            "url": "http://scikit-image.org/"
        },
        {
            "description": "\"Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "Theano",
            "url": "http://deeplearning.net/software/theano/"
        },
        {
            "description": "\"Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\"",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "Keras",
            "url": "http://keras.io/"
        },
        {
            "description": "An optimized, flexible, portable, regression and classification gradient boosting package that supports distributed training.",
            "tags": [
                "Python Packages",
                "Machine Learning Packages"
            ],
            "title": "XGBoost (Python)",
            "url": "http://xgboost.readthedocs.io/en/latest/python/python_intro.html"
        },
        {
            "description": "\"lifelines is a implementation of survival analysis in Python,\" built on top of pandas",
            "tags": [
                "Python Packages",
                "Statistics Packages"
            ],
            "title": "Lifelines",
            "url": "https://lifelines.readthedocs.io/en/latest/"
        },
        {
            "description": "An optimized, flexible, portable, regression and classification gradient boosting package that supports distributed training.",
            "tags": [
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "XGBoost (R)",
            "url": "http://xgboost.readthedocs.io/en/latest/R-package/index.html"
        },
        {
            "description": "\"The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for:  data splitting; pre-processing; feature selection; model tuning using resampling; variable importance estimation.\"",
            "tags": [
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "caret",
            "url": "http://topepo.github.io/caret/index.html"
        },
        {
            "description": "\"A data.frame processor/conditioner that prepares real-world data for predictive modeling in a statistically sound manner. Prepares variables so that data has fewer exceptional cases, making it easier to safely use models in production. Common problems 'vtreat' defends against: Inf, NA, too many categorical levels, rare categorical levels, new categorical levels (levels seen during application, but not during training).\"",
            "tags": [
                "R Packages",
                "Statistics Packages"
            ],
            "title": "vtreat",
            "url": "https://cran.r-project.org/web/packages/vtreat/index.html"
        },
        {
            "description": "\"A powerful and elegant high-level data visualization system inspired by Trellis graphics, with an emphasis on multivariate data. Lattice is sufficient for typical graphics needs, and is also flexible enough to handle most nonstandard requirements. See ?Lattice for an introduction.\"",
            "tags": [
                "R Packages",
                "Visualization Packages"
            ],
            "title": "Lattice",
            "url": "https://cran.r-project.org/web/packages/lattice/index.html"
        },
        {
            "description": "\"ggplot2 is a plotting system for R, based on the grammar of graphics, which tries to take the good parts of base and lattice graphics and none of the bad parts. It takes care of many of the fiddly details that make plotting a hassle (like drawing legends) as well as providing a powerful model of graphics that makes it easy to produce complex multi-layered graphics.\"",
            "tags": [
                "R Packages",
                "Visualization Packages"
            ],
            "title": "ggplot2",
            "url": "http://ggplot2.org/"
        },
        {
            "description": "\"Functions and datasets to support Venables and Ripley, 'Modern Applied Statistics with S' (4th edition, 2002).\"",
            "tags": [
                "R Packages",
                "Statistics Packages"
            ],
            "title": "MASS",
            "url": "https://cran.r-project.org/web/packages/MASS/index.html"
        },
        {
            "description": "\"A set of tools that solves a common set of problems: you need to break a big problem down into manageable pieces, operate on each piece and then put all the pieces back together. For example, you might want to fit a model to each spatial location or time point in your study, summarise data by panels or collapse high-dimensional arrays to simpler summary statistics. The development of 'plyr' has been generously supported by 'Becton Dickinson'.\"",
            "tags": [
                "R Packages"
            ],
            "title": "plyr",
            "url": "https://cran.r-project.org/web/packages/plyr/index.html"
        },
        {
            "description": "\"A fast, consistent tool for working with data frame like objects, both in memory and out of memory.\"",
            "tags": [
                "R Packages"
            ],
            "title": "dplyr",
            "url": "https://cran.r-project.org/web/packages/dplyr/index.html"
        },
        {
            "description": "\"Flexibly restructure and aggregate data using just two functions: melt and dcast (or acast).\"",
            "tags": [
                "R Packages"
            ],
            "title": "reshape2",
            "url": "https://cran.r-project.org/web/packages/reshape2/index.html"
        },
        {
            "author": "Charles Severance (with material adapted from Allen Downey)",
            "description": "\"The goal of this book is to provide an Informatics-oriented introduction to programming. The primary difference between a computer science approach and the Informatics approach taken in this book is a greater focus on using Python to solve data analysis problems common in the world of Informatics.\"",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Python for Informatics: Exploring Information",
            "url": "http://www.pythonlearn.com/book.php"
        },
        {
            "author": "Tom Augspurger",
            "description": "\"This series is about how to make effective use of pandas, a data analysis library for the Python programming language. It's targeted at an intermediate level: people who have some experince with pandas, but are looking to improve.\" Based on series of posts found here: <a href='http://tomaugspurger.github.io/modern-1.html'>http://tomaugspurger.github.io/modern-1.html</a> Payment optional.",
            "tags": [
                "Python Textbooks"
            ],
            "title": "Effective Pandas",
            "url": "https://leanpub.com/effective-pandas"
        },
        {
            "author": "Andrew Ng, Stanford University",
            "description": "\"This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.\"",
            "tags": [
                "Machine Learning Courses",
                "Beginner Machine Learning"
            ],
            "title": "Machine Learning",
            "url": "https://www.coursera.org/learn/machine-learning"
        },
        {
            "author": "Yaser S. Abu-Mostafa (Caltech)",
            "description": "\"Introductory Machine Learning course covering theory, algorithms and applications. Our focus is on real understanding, not just 'knowing.'\"",
            "tags": [
                "Machine Learning Courses",
                "Beginner Machine Learning"
            ],
            "title": "Learning From Data (Introductory Machine Learning)",
            "url": "https://www.edx.org/course/learning-data-introductory-machine-caltechx-cs1156x"
        },
        {
            "author": "Jim Fowler, The Ohio State University",
            "description": "\"This course is a first and friendly introduction to calculus, suitable for someone who has never seen the subject before, or for someone who has seen some calculus but wants to review the concepts and practice applying those concepts to solve problems.\"",
            "tags": [
                "Math Courses"
            ],
            "title": "Calculus One",
            "url": "https://www.coursera.org/learn/calculus1"
        },
        {
            "author": "Daphne Koller, Stanford University",
            "description": "\"In this class, you will learn the basics of the PGM representation and how to construct them, using both human knowledge and machine learning techniques; you will also learn algorithms for using a PGM to reach conclusions about the world from limited and noisy evidence, and for making good decisions under uncertainty. The class covers both the theoretical underpinnings of the PGM framework and practical skills needed to apply these techniques to new problems.\"  Sign up for a previous offering of the course.",
            "tags": [
                "Machine Learning Courses"
            ],
            "title": "Probabilistic Graphical Models",
            "url": "https://www.coursera.org/learn/probabilistic-graphical-models"
        },
        {
            "author": "Eric Grimson, John Guttag, and Ana Bell (MIT)",
            "description": "\"What you'll learn: A Notion of computation, The Python programming language, Some simple algorithms, Testing and debugging, An informal introduction to algorithmic complexity, Data structures\"",
            "tags": [
                "Python Courses",
                "Beginner Python"
            ],
            "title": "Introduction to Computer Science and Programming Using Python",
            "url": "https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x8"
        },
        {
            "author": "Eric Grimson, John Guttag, and Ana Bell, MIT",
            "description": "\"6.00.2x will teach you how to use computation to accomplish a variety of goals and provides you with a brief introduction to a variety of topics in computational problem solving . This course is aimed at students with some prior programming experience in Python and a rudimentary knowledge of computational complexity. You will spend a considerable amount of time writing programs to implement the concepts covered in the course. For example, you will write a program that will simulate a robot vacuum cleaning a room or will model the population dynamics of viruses replicating and drug treatments in a patient's body.\"",
            "tags": [
                "Python Courses"
            ],
            "title": "Introduction to Computational Thinking and Data Science",
            "url": "https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-3"
        },
        {
            "author": "Filip Schouwenaars, Microsoft",
            "description": "\"In this practical course, you will start from the very beginning, with basic arithmetic and variables, and learn how to handle data structures, such as Python lists, Numpy arrays, and Pandas DataFrames. Along the way, you'll learn about Python functions and control flow. Plus, you'll look at the world of data visualizations with Python and create your own stunning visualizations based on real data.\"",
            "tags": [
                "Python Courses",
                "Beginner Python"
            ],
            "title": "Introduction to Python for Data Science",
            "url": "https://www.edx.org/course/introduction-python-data-science-microsoft-dat208x-1"
        },
        {
            "author": "Authman Apatira, Microsoft",
            "description": "\"In this practical computer science course, you will build on your existing Python skills and learn how to manipulate data using Pandas, and build machine learning solutions in Python using the scikit-learn package.\"",
            "tags": [
                "Python Courses",
                "Machine Learning Courses"
            ],
            "title": "Programming with Python for Data Science",
            "url": "https://www.edx.org/course/programming-python-data-science-microsoft-dat210x"
        },
        {
            "author": "Filip Schouwenaars, Microsoft",
            "description": "\"This introduction to R programming course will help you master the basics of R. In seven sections, you will cover its basic syntax, making you ready to undertake your own first data analysis using R. Starting from variables and basic operations, you will eventually learn how to handle data structures such as vectors, matrices, data frames and lists. In the final section, you will dive deeper into the graphical capabilities of R, and create your own stunning data visualizations. No prior knowledge in programming or data science is required.\"",
            "tags": [
                "R Courses",
                "Beginner R"
            ],
            "title": "Introduction to R for Data Science",
            "url": "https://www.edx.org/course/introduction-r-data-science-microsoft-dat204x-0"
        },
        {
            "author": "Anders Stockmarr",
            "description": "\"In this course you will learn all you need to get up to speed with programming in R. Explore R data structures and syntaxes, see how to read and write data from a local file to a cloud-hosted database, work with data, get summaries, and transform them to fit your needs. Plus, find out how to perform predictive analytics using R and how to create visualizations using the popular ggplot2 package.\"",
            "tags": [
                "R Courses",
                "Machine Learning Courses"
            ],
            "title": "Programming with R for Data Science",
            "url": "https://www.edx.org/course/programming-r-data-science-microsoft-dat209x-0"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course will teach you the basics of working with Spark and will provide you with the necessary foundation for diving deeper into Spark. You'll learn about Spark's architecture and programming model, including commonly used APIs. After completing this course, you'll be able to write and debug basic Spark applications. This course will also explain how to use Spark's web user interface (UI), how to recognize common coding errors, and how to proactively prevent errors. The focus of this course will be Spark Core and Spark SQL.\"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Introduction to Apache Spark",
            "url": "https://www.edx.org/course/introduction-apache-spark-uc-berkeleyx-cs105x"
        },
        {
            "author": "Ameet Talwalkar, UCLA and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course introduces the underlying statistical and algorithmic principles required to develop scalable real-world machine learning pipelines. We present an integrated view of data processing by highlighting the various components of these pipelines, including exploratory data analysis, feature extraction, supervised learning, and model evaluation. You will gain hands-on experience applying these principles using Spark, a cluster computing system well-suited for large-scale machine learning tasks, and its packages spark.ml and spark.mllib. You will implement distributed algorithms for fundamental statistical models (linear regression, logistic regression, principal component analysis) while tackling key problems from domains such as online advertising and cognitive neuroscience.\"",
            "tags": [
                "Spark Courses",
                "Machine Learning Courses"
            ],
            "title": "Distributed Machine Learning with Apache Spark",
            "url": "https://www.edx.org/course/distributed-machine-learning-apache-uc-berkeleyx-cs120x"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"This statistics and data analysis course will attempt to articulate the expected output of data scientists and then teach students how to use PySpark (part of Spark) to deliver against these expectations. The course assignments include log mining, textual entity recognition, and collaborative filtering exercises that teach students how to manipulate data sets using parallel processing with PySpark.\"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Big Data Analysis with Apache Spark",
            "url": "https://www.edx.org/course/big-data-analysis-apache-spark-uc-berkeleyx-cs110x"
        },
        {
            "author": "Anthony D. Joseph, UC Berkeley and Jon Bates, Databricks",
            "description": "\"Gain a deeper understanding of Spark by learning about its APIs, architecture, and common use cases.  This statistics and data analysis course will cover material relevant to both data engineers and data scientists.  You'll learn how Spark efficiently transfers data across the network via its shuffle, details of memory management, optimizations to reduce compute costs, and more.  Learners will see several use cases for Spark and will work to solve a variety of real-world problems using public datasets.  After taking this course, you should have a thorough understanding of how Spark works and how you can best utilize its APIs to write efficient, scalable code.  You'll also learn about a wide variety of Spark's APIs, including the APIs in Spark Streaming. \"",
            "tags": [
                "Spark Courses"
            ],
            "title": "Advanced Apache Spark for Data Science and Data Engineering",
            "url": "https://www.edx.org/course/advanced-apache-spark-data-science-data-uc-berkeleyx-cs115x"
        },
        {
            "author": "Ameet Talwalkar, UCLA and Jon Bates, Databricks",
            "description": "\"Building on the core ideas presented in Distributed Machine Learning with Spark, this course covers advanced topics for training and deploying large-scale learning pipelines. You will study state-of-the-art distributed algorithms for collaborative filtering, ensemble methods (e.g., random forests), clustering and topic modeling, with a focus on model parallelism and the crucial tradeoffs between computation and communication.\"",
            "tags": [
                "Spark Courses",
                "Machine Learning Courses"
            ],
            "title": "Advanced Distributed Machine Learning with Apache Spark",
            "url": "https://www.edx.org/course/advanced-distributed-machine-learning-uc-berkeleyx-cs125x"
        },
        {
            "author": "Trevor Hastie and Rob Tibshirani, Stanford University",
            "description": "\"This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).\"",
            "tags": [
                "Statistics Courses",
                "Machine Learning Courses",
                "R Courses"
            ],
            "title": "Statistical Learning",
            "url": "http://online.stanford.edu/course/statistical-learning-Winter-16"
        },
        {
            "author": "David Robinson and Neo Christopher Chung (Princeton University)",
            "description": "\"This course combines video, HTML and interactive components to teach the statistical programming language R.\"",
            "tags": [
                "R Courses",
                "Beginner R"
            ],
            "title": "Data Analysis and Visualization Using R",
            "url": "http://varianceexplained.org/RData/"
        },
        {
            "author": "Brian Caffo, Johns Hopkins University",
            "description": "\"This class presents the fundamental probability and statistical concepts used in elementary data analysis. It will be taught at an introductory level for students with junior or senior college-level mathematical training including a working knowledge of calculus. A small amount of linear algebra and programming are useful for the class, but not required.\"Part I: <a href='https://www.coursera.org/learn/biostatistics'>Mathematical Biostatistics Boot Camp</a><br>Part II: <a href='https://www.coursera.org/learn/biostatistics-2'>Mathematical Biostatistics Boot Camp 2</a>",
            "tags": [
                "Statistics Courses"
            ],
            "title": "Mathematical Biostatistics Boot Camp",
            "url": "https://www.coursera.org/learn/biostatistics"
        },
        {
            "author": "mathematicalmonk",
            "description": "160 Machine Learning Short Lectures",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "Machine Learning Playlist",
            "url": "https://www.youtube.com/user/mathematicalmonk/playlists"
        },
        {
            "author": "Yaser Abu-Mostafa (Caltech)",
            "description": "Machine Learning course from Caltech. \"The fundamental concepts and techniques are explained in detail. The focus of the lectures is real understanding, not just 'knowing.'\"",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "Learning From Data",
            "url": "http://work.caltech.edu/lectures.html"
        },
        {
            "author": "Stanford University",
            "description": "\"This course is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification.\" Course includes a <a href='http://cs231n.github.io/python-numpy-tutorial/'>Python tutorial.</a>  Uses Python 2.",
            "tags": [
                "Machine Learning Lectures",
                "Python Tutorials"
            ],
            "title": "CS231n: Convolutional Neural Networks for Visual Recognition",
            "url": "http://cs231n.stanford.edu/"
        },
        {
            "author": "Joe Blitzstein, Hanspeter Pfister, Verena Kaynig-Fittkau (Harvard University)",
            "description": "Lectures from Harvard Extension School's Data Science class",
            "tags": [
                "Machine Learning Lectures",
                "Python Lectures"
            ],
            "title": "Data Science",
            "url": "http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml"
        },
        {
            "author": "mathematicalmonk",
            "description": "43 Short Probability Lectures",
            "tags": [
                "Probability Lectures"
            ],
            "title": "Probabilty Playlist",
            "url": "https://www.youtube.com/watch?v=Tk4ubu7BlSk&list=PL17567A1A3F5DB5E4"
        },
        {
            "author": "mathematicalmonk",
            "description": "54 Short Information Theory Lectures",
            "tags": [
                "Information Theory Lectures"
            ],
            "title": "Information Theory Playlist",
            "url": "https://www.youtube.com/watch?v=UrefKMSEuAI&list=PLE125425EC837021F"
        },
        {
            "author": "Andrew Gelman",
            "description": "This is a blog by the author of Bayesian Data Analysis.",
            "tags": [
                "Statistics Blogs"
            ],
            "title": "Statistical Modeling, Causal Inference, and Social Science",
            "url": "http://andrewgelman.com/"
        },
        {
            "author": "John D. Cook",
            "description": "A blog about applied math, statistics, and software development.",
            "tags": [
                "Statistics Blogs",
                "Programming Blogs"
            ],
            "title": "John D. Cook",
            "url": "http://www.johndcook.com/blog/"
        },
        {
            "author": "Michael Kennedy",
            "description": "\"The show covers a wide array of Python topics as well as many related topics (e.g. MongoDB, AngularJS, DevOps).\"",
            "tags": [
                "Python Podcasts"
            ],
            "title": "Talk Python to Me",
            "url": "https://talkpython.fm/"
        },
        {
            "author": "Tobias Macey and Chris Patti",
            "description": "\"Podcast.init is a show about the Python programming language and the awesome community that has grown up around it. Our goal is to share discussions on subjects ranging from interesting and useful tools and products to social and ethical issues such as diversity and inclusiveness in tech.\"",
            "tags": [
                "Python Podcasts"
            ],
            "title": "Podcast.\\_\\_init\\_\\_",
            "url": "http://podcastinit.com/"
        },
        {
            "author": "Katherine Gorman and Ryan Adams (Harvard University)",
            "description": "\"Talking Machines is your window into the world of machine learning. Your hosts, Katherine Gorman and Ryan Adams, bring you clear conversations with experts in the field, insightful discussions of industry news, and useful answers to your questions.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "Talking Machines",
            "url": "http://www.thetalkingmachines.com/"
        },
        {
            "author": "Jonathon Morgan, Vidya Spandana, and Chris Albon",
            "description": "\"Partially Derivative is a weekly podcast, blog, and newsletter about the data science in the world around us. We geek out on silly data stories, interview amazing people doing interesting work, and drink beer.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "Partially Derivative",
            "url": "http://partiallyderivative.com/"
        },
        {
            "author": "Roger Peng (Johns Hopkins University) and Hilary Parker",
            "description": "Podcast on Data Science, Statistics, Python, and R in academia and industry.",
            "tags": [
                "Statistics Podcasts"
            ],
            "title": "Not So Standard Deviations",
            "url": "https://soundcloud.com/nssd-podcast"
        },
        {
            "author": "Ben Lorica (O'Reilly)",
            "description": "\"The O'Reilly Data Show Podcast: Danny Bickson on recommenders, data science, and applications of machine learning.\"",
            "tags": [
                "Machine Learning Podcasts"
            ],
            "title": "O'Reilly Data Show Podcast",
            "url": "https://www.oreilly.com/topics/oreilly-data-show-podcast"
        },
        {
            "author": "Nathan Yau",
            "description": "\"FlowingData explores how statisticians, designers, data scientists, and others use analysis, visualization, and exploration to understand data and ourselves.\"  Paid membership optional for visualization tutorials.",
            "tags": [
                "Visualization Blogs"
            ],
            "title": "Flowing Data",
            "url": "http://flowingdata.com/"
        },
        {
            "author": "Hadley Wickham",
            "description": "Material for Hadley Wickham's course on visualization at Rice University.",
            "tags": [
                "Visualization Misc"
            ],
            "title": "Data Visualisation",
            "url": "http://had.co.nz/stat645/"
        },
        {
            "author": "Unknown",
            "description": "Flow chart for choosing a chart type.",
            "tags": [
                "Visualization Misc",
                "Beginner Visualization"
            ],
            "title": "Choosing a Data Chart",
            "url": "http://img.labnol.org/di/data-chart-type.png"
        },
        {
            "author": "Cliburn Chan (Duke University)",
            "description": "Thorough tutorial of Python from basics through scientific stack.  Uses Python 3.",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Computational Statistics in Python",
            "url": "http://people.duke.edu/~ccc14/sta-663-2016/index.html"
        },
        {
            "author": "Ujjwal Karn",
            "description": "\"This repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. \"",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Machine Learning & Deep Learning Tutorials",
            "url": "https://github.com/ujjwalkarn/Machine-Learning-Tutorials"
        },
        {
            "author": "Ujjwal Karn",
            "description": "\"This repo contains a curated list of Python tutorials for Data Science, NLP and Machine Learning.\"",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Python Data Science Tutorials",
            "url": "https://github.com/ujjwalkarn/DataSciencePython"
        },
        {
            "author": "qinwf",
            "description": "A curated list of awesome R packages and tools.",
            "tags": [
                "R Packages"
            ],
            "title": "Awesome R",
            "url": "https://github.com/qinwf/awesome-R"
        },
        {
            "author": "Vinta",
            "description": "A curated list of awesome Python frameworks, libraries, software and resources.",
            "tags": [
                "Python Packages"
            ],
            "title": "Awesome Python",
            "url": "https://github.com/vinta/awesome-python"
        },
        {
            "author": "Joseph Misiti",
            "description": "A curated list of awesome machine learning frameworks, libraries and software (by language). ",
            "tags": [
                "Python Packages",
                "R Packages",
                "Machine Learning Packages"
            ],
            "title": "Awesome Machine Learning",
            "url": "https://github.com/josephmisiti/awesome-machine-learning"
        },
        {
            "author": "The R Project for Statistical Computing",
            "description": "\"The R Journal is the open access, refereed journal of the R project for statistical computing. It features short to medium length articles covering topics that might be of interest to users or developers of R, including: short introductions to R extension packages; hints for programming in R; hints for newcomers explaining aspects of R that might not be so obvious from reading the manuals and FAQs; demonstrating how a new or existing technique can be applied in an area of current interest using R, providing a fresh view of such analyses in R that is of benefit beyond the specific application.\"",
            "tags": [
                "R Packages"
            ],
            "title": "The R Journal",
            "url": "https://journal.r-project.org/"
        },
        {
            "author": "",
            "description": "A curated list of awesome TensorFlow experiments, libraries, and projects. ",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Awesome TensorFlow",
            "url": "https://github.com/jtoy/awesome-tensorflow"
        },
        {
            "author": "Carl Vogel",
            "description": "Python implementations of examples from Machine Learning for Hackers. Uses Python 2.",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Will it Python? Machine Learning for Hackers",
            "url": "https://github.com/carljv/Will_it_Python/tree/master/MLFH"
        },
        {
            "author": "Chris Burns, Christophe Combelles, Emmanuelle Gouillart, and Ga\u00ebl Varoquaux",
            "description": "\"Tutorials on the scientific Python ecosystem: a quick introduction to central tools and techniques. The different chapters each correspond to a 1 to 2 hours course with increasing level of expertise, from beginner to expert.\"",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Scipy lecture notes",
            "url": "http://www.scipy-lectures.org/"
        },
        {
            "author": "Python Software Foundation",
            "description": "Tutorials and Documentation for Beginner, Moderate, and Advanced Users.  Available for Python 2 and 3.",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "Official Python Documentation",
            "url": "https://www.python.org/doc/"
        },
        {
            "author": "Kunal Jain",
            "description": "Covers basics through predictive modeling in Python 2.",
            "tags": [
                "Python Tutorials",
                "Beginner Python"
            ],
            "title": "A Complete Tutorial to Learn Data Science with Python from Scratch",
            "url": "http://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/"
        },
        {
            "author": "Kunal Jain",
            "description": "\"In this guide, I will use NumPy, Matplotlib, Seaborn and Pandas to perform data exploration.\" Uses Python 2.",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Ultimate guide for Data Exploration in Python using NumPy, Matplotlib and Pandas",
            "url": "http://www.analyticsvidhya.com/blog/2015/04/comprehensive-guide-data-exploration-sas-using-python-numpy-scipy-matplotlib-pandas/"
        },
        {
            "author": "Michael Nielsen",
            "description": "\"The book will teach you about: Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data; Deep learning, a powerful set of techniques for learning in neural networks.\"  Uses Python 2.",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Neural Networks and Deep Learning",
            "url": "http://neuralnetworksanddeeplearning.com/"
        },
        {
            "author": "Ian Goodfellow, Yoshua Bengio and Aaron Courville",
            "description": "\"The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.\" A pdf version appears to be available here: https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf",
            "tags": [
                "Machine Learning Textbooks"
            ],
            "title": "Deep Learning",
            "url": "http://www.deeplearningbook.org/"
        },
        {
            "author": "John Mount and Nina Zumel",
            "description": "The Win-Vector LLC data science blog",
            "tags": [
                "Statistics Blogs",
                "Machine Learning Blogs",
                "Programming Blogs"
            ],
            "title": "Win-Vector",
            "url": "http://www.win-vector.com/blog/"
        },
        {
            "author": "Allen Downey",
            "description": "Allen Downey's PyCon tutorial for computational statistics in Python.",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "Allen Downey - Computational Statistics - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=VR52vSbHBAk"
        },
        {
            "author": "Allen Downey",
            "description": "Allen Downey's PyCon tutorial for Bayesian Statistics in Python.",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "Allen Downey - Bayesian statistics made simple - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=6GV5bTCLC8g"
        },
        {
            "author": "Julia Ferraioli, Amy Unruh, Eli Bixby",
            "description": "\"Machine learning can be an intimidating subject. In this session, we'll get practical, hands-on experience with core concepts in machine learning with TensorFlow, an open source deep learning library. We\u2019ll introduce the basics of TensorFlow, including how to ingest and prepare raw data for use, run a variety of algorithms to gain insight from the data, and have some fun with visualization.\"",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Diving into Machine Learning through TensorFlow - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=GZBIPwdGtkk"
        },
        {
            "author": "Jean Francois Puget",
            "description": "Tutorial on preparing data sets using Pandas",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Tidy Data In Python",
            "url": "https://www.ibm.com/developerworks/community/blogs/jfp/entry/Tidy_Data_In_Python?lang=en"
        },
        {
            "author": "Robert I. Kabacoff",
            "description": "\"R is an elegant and comprehensive statistical and graphical programming language. Unfortunately, it can also have a steep learning curve. I created this website for both current R users, and experienced users of other statistical packages (e.g., SAS, SPSS, Stata) who would like to transition to R. My goal is to help you quickly access this language in your work.\"  See <a href='http://www.statmethods.net/graphs/index.html'>Basic Graphs</a> and <a href='http://www.statmethods.net/advgraphs/index.html'>Advanced Graphs</a> for visualization examples.",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "Quick-R",
            "url": "http://www.statmethods.net/"
        },
        {
            "author": "",
            "description": "\"A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.\"",
            "tags": [
                "R Tutorials"
            ],
            "title": "Tidy Data",
            "url": "http://vita.had.co.nz/papers/tidy-data.pdf"
        },
        {
            "author": "Aarshay Jain",
            "description": "\"This article focuses on providing 12 ways for data manipulation in Python. I've also shared some tips & tricks which will allow you to work faster.\"",
            "tags": [
                "Python Tutorials"
            ],
            "title": "12 Useful Pandas Techniques in Python for Data Manipulation",
            "url": "http://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/"
        },
        {
            "author": "Skipper Seabold",
            "description": "Example of using Pandas and scikit-learn to classify whether a person makes over 50K a year.",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Using pandas and scikit-learn for classification tasks",
            "url": "https://github.com/jseabold/depy/blob/master/pandas_sklearn_rendered.ipynb"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"This is just a small but growing collection of pandas snippets that I find occasionally and particularly useful\"",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Things in Pandas I Wish I'd Known Earlier",
            "url": "http://nbviewer.jupyter.org/github/rasbt/python_reference/blob/master/tutorials/things_in_pandas.ipynb"
        },
        {
            "author": "Chris Moffitt",
            "description": "\"This article will focus on explaining the pandas pivot_table function and how to use it for your data analysis.\"",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Pandas Pivot Table Explained",
            "url": "http://pbpython.com/pandas-pivot-table-explained.html"
        },
        {
            "author": "Philipp Rudiger",
            "description": "\"In this notebook we'll look at interfacing between the composability and ability to generate complex visualizations that HoloViews provides and the great looking plots incorporated in the seaborn library. Along the way we'll explore how to wrap different types of data in a number of Seaborn View types, including: Distribution Views, Bivariate Views, TimeSeries Views\"",
            "tags": [
                "Python Tutorials",
                "Visualization Tutorials"
            ],
            "title": "Exploring Seaborn and Pandas based plot types in HoloViews",
            "url": "http://philippjfr.com/blog/seabornviews/"
        },
        {
            "author": "yhat",
            "description": "\"This is a post about pandasql, a library we're open-sourcing for Python which lets you use SQL on pandas dataframes.\"",
            "tags": [
                "Python Tutorials"
            ],
            "title": "SQL for pandas DataFrames",
            "url": "http://blog.yhat.com/posts/pandasql-sql-for-pandas-dataframes.html"
        },
        {
            "author": "Zac Stewart",
            "description": "\"The following is a moderately detailed explanation and a few examples of how I use pipelining when I work on competitions.\"",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Using scikit-learn Pipelines and FeatureUnions",
            "url": "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
        },
        {
            "author": "Zac Stewart",
            "description": "\"To demonstrate text classification with scikit-learn, we're going to build a simple spam filter. While the filters in production for services like Gmail are vastly more sophisticated, the model we'll have by the end of this tutorial is effective, and surprisingly accurate.\"",
            "tags": [
                "Python Tutorials",
                "Machine Learning Tutorials"
            ],
            "title": "Document Classification with scikit-learn",
            "url": "http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html"
        },
        {
            "author": "Kyle and Linh Da",
            "description": "\"Data Skeptic is a podcast that alternates between short mini episodes and longer interviews. For the mini-episodes, Kyle and Linh Da explore basic data science concepts. Longer interviews feature practitioners and experts on interesting topics related to data, all through the eye of scientific skepticism.\"",
            "tags": [
                "Statistics Podcasts",
                "Beginner Statistics"
            ],
            "title": "Data Skeptic",
            "url": "http://dataskeptic.com/"
        },
        {
            "author": "John D. Cook",
            "description": "\"The following diagram summarizes conjugate prior relationships for a number of common sampling distributions.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Diagram of Bayesian Conjugate Priors",
            "url": "http://www.johndcook.com/blog/conjugate_prior_diagram/"
        },
        {
            "author": "Allen Downey",
            "description": "A distillation of hypothesis testing into a single framework.  A nice alternative to memorizing lots of classical tests.  Follow up posts <a href='http://allendowney.blogspot.com/2011/06/more-hypotheses-less-trivia.html'>here with lots of exmaples</a> and <a href='http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html'>here</a>",
            "tags": [
                "Statistics Misc"
            ],
            "title": "There is only one test!",
            "url": "http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html"
        },
        {
            "author": "Ben Klemens",
            "description": "\"This project lists open-form narratives and the closed-form distributions that approximate them. Its intent is to help you build estimable statistical models on a sound micro-level foundation.\"",
            "tags": [
                "Statistics Misc",
                "Beginner Statistics"
            ],
            "title": "A Table of Narratives and Generated Distributions",
            "url": "http://b-k.github.io/narratives-distributions/index.html"
        },
        {
            "author": "Kaggle",
            "description": "Interviews of Kaggle Compeition top finishers, and scripts shared by competitors.",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "No Free Hunch",
            "url": "http://blog.kaggle.com/"
        },
        {
            "author": "Sebatian Raschka",
            "description": "Blog of the author of the 'Python Machine Learning' book",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "Sebatian Raschka's Blog",
            "url": "http://sebastianraschka.com/blog/index.html"
        },
        {
            "author": "Sebatian Raschka",
            "description": "Part I: <a href='http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html'>General ideas behind model evaluation in supervised machine learning</a><br>Part 2: <a href='http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html'>Some advanced techniques for model evaluation</a>",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Model evaluation, model selection, and algorithm selection in machine learning",
            "url": "http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html"
        },
        {
            "author": "Zygmunt Zaj\u0105c",
            "description": "\"This site is brought to you by the letters \u201cM\u201d and \u201cL\u201d. It is meant to tackle interesting topics in machine learning while being entertaining and easy to read and understand. FastML probably grew out of a frustration with papers you need a PhD in math to understand and with either no code or half-baked Matlab implementation of homework-assignment quality. We understand that some cutting-edge researchers might have no interest in providing the goodies for free, or just no interest in such down-to-earth matters. But we don't have time nor desire to become experts in every machine learning topic. Fortunately, there is quite a lot of good software with acceptable documentation.\"",
            "tags": [
                "Machine Learning Blogs"
            ],
            "title": "Fast ML",
            "url": "http://fastml.com/"
        },
        {
            "author": "Chris Fonnesbeck",
            "description": "A worked exmaple of Hierarchical Modeling using pystan",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "A Primer on Bayesian Multilevel Modeling using PyStan",
            "url": "http://mc-stan.org/documentation/case-studies/radon.html"
        },
        {
            "author": "Yuan Tang",
            "description": "\"Scikit Flow is a simplified interface for TensorFlow, to get people started on predictive analytics and data mining. It helps smooth the transition from the Scikit-learn world of one-liner machine learning into the more open world of building different shapes of ML models. You can start by using fit/predict and slide into TensorFlow APIs as you are getting comfortable. It\u2019s Scikit-learn compatible so you can also benefit from Scikit-learn features like GridSearch and Pipeline.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Introduction to Scikit Flow",
            "url": "http://terrytangyuan.github.io/2016/03/14/scikit-flow-intro/"
        },
        {
            "author": "yhat",
            "description": "\"Ever heard people at your office talking about AUC, ROC, or TPR but been too shy to ask what the heck they're talking about? Well lucky for you we're going to be diving into the wonderful world of binary classification evaluation today. In particular, we'll be discussing ROC curves.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "ROC Curves in Python and R",
            "url": "http://blog.yhat.com/posts/roc-curves.html"
        },
        {
            "author": "Kim Larsen",
            "description": "\"Despite its lack of popularity in the data science community, GAM is a powerful and yet simple technique. Hence, the purpose of this post is to convince more data scientists to use GAM. Of course, GAM is no silver bullet, but it is a technique you should add to your arsenal. Here are three key reasons: Easy to interpret; Flexible predictor functions can uncover hidden patterns in the data; Regularization of predictor functions helps avoid overfitting.\"",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "GAM: The Predictive Modeling Silver Bullet",
            "url": "http://multithreaded.stitchfix.com/blog/2015/07/30/gam/"
        },
        {
            "author": "Ando Saabas",
            "description": "Example of using package treeinterpreter for insight into a scikit-learn RandomForest",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Random forest interpretation with scikit-learn",
            "url": "http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/"
        },
        {
            "author": "Kaggle user Triskelion",
            "description": "\"Model ensembling is a very powerful technique to increase accuracy on a variety of ML tasks. In this article I will share my ensembling approaches for Kaggle Competitions.\"",
            "tags": [
                "Machine Learning Misc"
            ],
            "title": "Kaggle Ensembling Guide",
            "url": "http://mlwave.com/kaggle-ensembling-guide/"
        },
        {
            "author": "Sebastian Raschka",
            "description": "A collection of tutorials and examples for solving and understanding machine learning and pattern classification tasks",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Pattern Classification",
            "url": "https://github.com/rasbt/pattern_classification"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"When we are applying machine learning algorithms to real-world applications, our computer hardware often still constitutes the major bottleneck of the learning process. Of course, we all have access to supercomputers, Amazon EC2, Apache Spark, etc. However, out-of-core learning via Stochastic Gradient Descent can still be attractive if we'd want to update our model on-the-fly ('online-learning'), and in this notebook, I want to provide some examples of how we can implement an 'out-of-core' approach using scikit-learn. I compiled the following code examples for personal reference, and I don't intend it to be a comprehensive reference for the underlying theory, but nonetheless, I decided to share it since it may be useful to one or the other!\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Out-of-core Learning and Model Persistence using scikit-learn",
            "url": "https://github.com/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
        },
        {
            "author": "Mark Needham",
            "description": "Tutorial on how to convert text data for training with a scikit-learn RandomForest Classifier",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Python: scikit-learn \u2013 Training a classifier with non numeric features",
            "url": "https://www.webcodegeeks.com/python/python-scikit-learn-training-classifier-non-numeric-features/"
        },
        {
            "author": "Sebastian Raschka",
            "description": "\"Here, I want to present a simple and conservative approach of implementing a weighted majority rule ensemble classifier in scikit-learn that yielded remarkably good results when I tried it in a kaggle competition.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Implementing a Weighted Majority Rule Ensemble Classifier",
            "url": "http://sebastianraschka.com/Articles/2014_ensemble_classifier.html"
        },
        {
            "author": "Nicolas Kruchten",
            "description": "\"A different way to look at graph analysis and visualization, as an introduction to a few cool algorithms: Truncated SVD, K-Means and t-SNE with a practical walkthrough using scikit-learn and friends numpy and bokeh, and finishing off with some more general commentary on this approach to data analysis.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Data Science and (Unsupervised) Machine Learning with scikit-learn",
            "url": "http://opensource.datacratic.com/mtlpy50/"
        },
        {
            "author": "Zygmunt Zaj\u0105c",
            "description": "\"Calibration is applicable in case a classifier outputs probabilities. Apparently some classifiers have their typical quirks - for example, they say boosted trees and SVM tend to predict probabilities conservatively, meaning closer to mid-range than to extremes. If your metric cares about exact probabilities, like logarithmic loss does, you can calibrate the classifier, that is post-process the predictions to get better estimates.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Classifier calibration with Platt's scaling and isotonic regression",
            "url": "http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/"
        },
        {
            "author": "Edwin Chen",
            "description": "\"A couple weeks ago, Facebook launched a link prediction contest on Kaggle, with the goal of recommending missing edges in a social graph. I love investigating social networks, so I dug around a little, and since I did well enough to score one of the coveted prizes, I\u2019ll share my approach here.\"",
            "tags": [
                "Machine Learning Tutorials"
            ],
            "title": "Edge Prediction in a Social Graph: My Solution to Facebook's User Recommendation Contest on Kaggle",
            "url": "http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/"
        },
        {
            "author": "Austin Rochford",
            "description": "\"In this post, we\u2019ll explore a Bayesian approach to nonparametric regression, which allows us to model complex functions with relatively weak assumptions.\" Extends scikit-learn.",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "Nonparametric Bayesian Regression with Gaussian Processes",
            "url": "http://austinrochford.com/posts/2014-03-23-bayesian-nonparamtric-regression-gp.html"
        },
        {
            "author": "Max Kuhn",
            "description": "\"I'll demonstrate how Bayesian optimization and Gaussian process models can be used as an alternative.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Bayesian Optimization of Machine Learning Models",
            "url": "http://blog.revolutionanalytics.com/2016/06/bayesian-optimization-of-machine-learning-models.html"
        },
        {
            "author": "John Mount",
            "description": "\"This article is a demonstration the use of the R vtreat variable preparation package followed by caret controlled training.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "A demonstration of vtreat data preparation",
            "url": "http://www.win-vector.com/blog/2016/06/a-demonstration-of-vtreat-data-preparation/"
        },
        {
            "author": "Nina Zumel",
            "description": "Part I: <a href='http://www.win-vector.com/blog/2016/05/pcr_part1_xonly'>The Standard Method</a><br>Part II: <a href='http://www.win-vector.com/blog/2016/05/pcr_part2_yaware/'>Y-Aware Methods</a><br>Part III: <a href='http://www.win-vector.com/blog/2016/05/pcr_part3_pickk/'>Picking the Number of Components</a>",
            "tags": [
                "Statistics Tutorials",
                "R Tutorials"
            ],
            "title": "Principal Components Regression",
            "url": "http://www.win-vector.com/blog/2016/05/pcr_part1_xonly/"
        },
        {
            "author": "John Mount",
            "description": "Part 1: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart1/'>Setting up the specific problem for modeling.</a><br>Part 2: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart2/'>In-training set measures</a><br>Part 3: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart3/'>Out of sample procedures</a><br>Part 4: <a href='http://www.win-vector.com/blog/2015/09/willyourmodelworkpart4/'>Cross-validation techniques</a>",
            "tags": [
                "Statistics Misc"
            ],
            "title": "How do you know if your model is going to work?",
            "url": "http://www.win-vector.com/blog/2015/09/willyourmodelworkpart1/"
        },
        {
            "author": "John Mount",
            "description": "Sample size calculation and visualization for power and significance specifications.",
            "tags": [
                "Statistics Misc",
                "R Tutorials"
            ],
            "title": "A clear picture of power and significance in A/B tests",
            "url": "http://www.win-vector.com/blog/2014/05/a-clear-picture-of-power-and-significance-in-ab-tests/"
        },
        {
            "author": "John Mount",
            "description": "\"In this article we are going to work a simple (but important) problem where (for once) the Bayesian calculations are in fact easier than the frequentist ones.\"",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "Frequentist inference only seems easy",
            "url": "http://www.win-vector.com/blog/2014/07/frequenstist-inference-only-seems-easy/"
        },
        {
            "author": "Nina Zumel",
            "description": "Tutorial for graphing with ggplot2 in R",
            "tags": [
                "Visualization Tutorials",
                "R Tutorials"
            ],
            "title": "The Extra Step: Graphs for Communication versus Exploration",
            "url": "http://www.win-vector.com/blog/2014/01/the-extra-step-graphs-for-communication-versus-exploration/"
        },
        {
            "author": "Joseph Rickert",
            "description": "\"Performing feature selection with GAs requires conceptualizing the process of feature selection as an optimization problem and then mapping it to the genetic framework of random variation and natural selection.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Feature Selection with caret's Genetic Algorithm Option",
            "url": "http://blog.revolutionanalytics.com/2015/12/caret-genetic.html"
        },
        {
            "author": "Joseph Rickert",
            "description": "\"Here, I fit a randomForest model to eight features from the UCI MPG data set and use the randomForestInfJack() function to calculate the infinitesimal Jackknife estimator.\"",
            "tags": [
                "Machine Learning Tutorials",
                "R Tutorials"
            ],
            "title": "Confidence Intervals for Random Forests",
            "url": "http://blog.revolutionanalytics.com/2016/03/confidence-intervals-for-random-forest.html"
        },
        {
            "author": "Sharon Machlis",
            "description": "\"Our aim here isn't R mastery, but giving you a path to start using R for basic data work: Extracting key statistics out of a data set, exploring a data set with basic graphics and reshaping data to make it easier to analyze.\"",
            "tags": [
                "Beginner R",
                "R Tutorials"
            ],
            "title": "Beginner's guide to R: Introduction",
            "url": "http://www.computerworld.com/article/2497143/business-intelligence/business-intelligence-beginner-s-guide-to-r-introduction.html"
        },
        {
            "author": "Sharon Machlis",
            "description": "\"Learn how to wrangle data, including using R's transform, apply and mapply functions, along with sorting, grouping by date range and reshaping. We also take you through some dplyr basics.\"",
            "tags": [
                "Beginner R",
                "R Tutorials"
            ],
            "title": "Advanced Beginner's Guide to R",
            "url": "http://www.computerworld.com/resources/106345/advanced-beginners-guide-to-r.html"
        },
        {
            "author": "Max Woolf",
            "description": "Tutorial for making nicely styled charts with R and ggplot2.",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "An Introduction on How to Make Beautiful Charts With R and ggplot2",
            "url": "http://minimaxir.com/2015/02/ggplot-tutorial/"
        },
        {
            "author": "Max Woolf",
            "description": "\"Here are some tips and tutorials on how to make such visualizations.\"",
            "tags": [
                "R Tutorials",
                "Visualization Tutorials"
            ],
            "title": "How to Visualize New York City Using Taxi Location Data and ggplot2",
            "url": "http://minimaxir.com/2015/11/nyc-ggplot2-howto/"
        },
        {
            "author": "Krzysztof Osiewalski",
            "description": "\"In this article we give some hints on how to use your machine in most efficient way while programming in R and when this can be achieved.\"",
            "tags": [
                "R Tutorials"
            ],
            "title": "Unleash the power of your multi-core CPU with R",
            "url": "http://www.marketingdistillery.com/2014/11/29/unleash-the-power-of-your-multi-core-cpu-with-r/"
        },
        {
            "author": "Kim Larsen",
            "description": "Tutorial on using Bayesian structural time series models.",
            "tags": [
                "R Tutorials",
                "Statistics Tutorials"
            ],
            "title": "Sorry ARIMA, but I\u2019m Going Bayesian",
            "url": "http://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/"
        },
        {
            "author": "Max Kuhn",
            "description": "\"Max Kuhn, author of Applied Predictive Modeling and caret package, will talk about the practice of predictive modeling. The practice of predictive modeling defines the process of developing a model in a way that we can understand and quantify the model's prediction accuracy on future data.\"",
            "tags": [
                "Machine Learning Lectures"
            ],
            "title": "R: Applied Predictive Modeling",
            "url": "https://www.youtube.com/watch?v=99lnTku75Pc"
        },
        {
            "author": "Jake Vanderplas",
            "description": "Part I: <a href='http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/'>A Practical Introduction</a><br><br>Part II: <a href='http://jakevdp.github.io/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/'>When Results Differ</a><br>Part III: <a href='http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/'>Confidence, Credibility, and why Frequentism and Science do not Mix</a><br>Part IV: <a href='http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/'>How to be a Bayesian in Python</a><br>Part V: <a href='https://jakevdp.github.io/blog/2015/08/07/frequentism-and-bayesianism-5-model-selection/'>Model Selection</a>",
            "tags": [
                "Statistics Tutorials",
                "Python Tutorials"
            ],
            "title": "Frequentism and Bayesianism",
            "url": "http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/"
        },
        {
            "author": "Jake Vanderplas",
            "description": "\"Statistics has the reputation of being difficult to understand, but using some simple Python skills it can be made much more intuitive. This talk will cover several sampling-based approaches to solving statistical problems, and show you that if you can write a for-loop, you can do statistics.\"",
            "tags": [
                "Statistics Lectures",
                "Beginner Statistics"
            ],
            "title": "Statistics for Hackers - PyCon 2016",
            "url": "https://www.youtube.com/watch?v=L5GVOFAYi8k"
        },
        {
            "author": "Jake Vanderplas",
            "description": "\"Statistics has the reputation of being difficult to understand, but using some simple Python skills it can be made much more intuitive. This talk will cover several sampling-based approaches to solving statistical problems, and show you that if you can write a for-loop, you can do statistics.\"",
            "tags": [
                "Machine Learning Tutorials",
                "Python Tutorials"
            ],
            "title": "PyCon 2015 Introduction to Scikit-Learn tutorial",
            "url": "http://nbviewer.jupyter.org/github/jakevdp/sklearn_pycon2015/blob/master/notebooks/Index.ipynb"
        },
        {
            "author": "OverAPI.com",
            "description": "Quick reference for regular expressions",
            "tags": [
                "Programming Misc"
            ],
            "title": "RegEx Cheat Sheet",
            "url": "http://overapi.com/regex"
        },
        {
            "author": "Jay Feng",
            "description": "Demonstration of how to apply a function to pandas in parallel.",
            "tags": [
                "Python Tutorials"
            ],
            "title": "Python Pandas Functions in Parallel",
            "url": "http://www.racketracer.com/2016/07/06/pandas-in-parallel/"
        },
        {
            "author": "Evan Miller",
            "description": "\"Intuitive statistical calculators, ideal for planning and analyzing A/B tests.\"",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Evan's Awesome A/B Tools",
            "url": "http://www.evanmiller.org/ab-testing/"
        },
        {
            "author": "Andrew Gelman",
            "description": "Demonstration of how informative priors can escape the multiple comparison problem.",
            "tags": [
                "Statistics Misc"
            ],
            "title": "Bayesian inference completely solves the multiple comparisons problem",
            "url": "http://andrewgelman.com/2016/08/22/bayesian-inference-completely-solves-the-multiple-comparisons-problem/"
        }
    ]
}
